{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a156b5",
   "metadata": {},
   "source": [
    "# Proyecto Semestral: Introducci√≥n a Redes Neuronales y Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85453d60",
   "metadata": {},
   "source": [
    "En este documento se aplica, con la mayor fidelidad posible lo abordado en el paper. El c√≥digo esta separado en las siguientes secciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c0a70",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3709522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# IMPORTS\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Sequence, Mapping, Union\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks, optimizers, Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a23279",
   "metadata": {},
   "source": [
    "## Generaci√≥n del dataset\n",
    "\n",
    "* Indicadores t√©cnicos\n",
    "* Target(y) y splits temporales\n",
    "* Escalado y construcci√≥n de ventanas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tech_indicators(\n",
    "    data,\n",
    "    price_col: str = \"Close\",\n",
    "    high_col: str = \"High\",\n",
    "    low_col: str = \"Low\",\n",
    "    vol_col: str = \"Volume\",\n",
    "    safe: bool = True,\n",
    "    reset_index: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera un conjunto completo de indicadores t√©cnicos financieros a partir de datos OHLCV.\n",
    "    \n",
    "    Calcula m√°s de 40 indicadores t√©cnicos incluyendo medias m√≥viles, osciladores,\n",
    "    indicadores de momentum, volatilidad y volumen. Todos los indicadores se calculan\n",
    "    de forma que eviten fuga de datos temporal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.Series or pd.DataFrame\n",
    "        Datos de entrada. Puede ser una Serie con precios de cierre o un DataFrame\n",
    "        con columnas OHLCV (Open, High, Low, Close, Volume).\n",
    "    price_col : str, default=\"Close\"\n",
    "        Nombre de la columna que contiene el precio de cierre.\n",
    "    high_col : str, default=\"High\"\n",
    "        Nombre de la columna que contiene el precio m√°ximo.\n",
    "    low_col : str, default=\"Low\"\n",
    "        Nombre de la columna que contiene el precio m√≠nimo.\n",
    "    vol_col : str, default=\"Volume\"\n",
    "        Nombre de la columna que contiene el volumen.\n",
    "    safe : bool, default=True\n",
    "        Si True, desplaza todos los features 1 d√≠a hacia adelante para evitar\n",
    "        fuga de datos (anti-fuga). Esto asegura que para predecir t+1 solo se\n",
    "        use informaci√≥n hasta t.\n",
    "    reset_index : bool, default=True\n",
    "        Si True, convierte el √≠ndice datetime en una columna \"Date\" y resetea el √≠ndice.\n",
    "        Si False, mantiene el √≠ndice como DatetimeIndex.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas:\n",
    "        - Date: Fecha (si reset_index=True)\n",
    "        - Price: Precio de cierre\n",
    "        - Open, High, Low, Volume: Datos originales (si disponibles)\n",
    "        - SMA_5, SMA_10, SMA_20, SMA_50, SMA_200: Medias m√≥viles simples\n",
    "        - EMA_5, EMA_10, EMA_20, EMA_50: Medias m√≥viles exponenciales\n",
    "        - MACD, MACD_signal, MACD_hist: Indicadores MACD\n",
    "        - ROC_1, ROC_5, ROC_10: Rate of Change\n",
    "        - MOM_1, MOM_5, MOM_10: Momentum\n",
    "        - RSI_14: Relative Strength Index\n",
    "        - VOL_20: Volatilidad logar√≠tmica\n",
    "        - BB_BW, BB_PB: Bollinger Bands (ancho y posici√≥n)\n",
    "        - STOCH_K, STOCH_D: Estoc√°stico\n",
    "        - WILLR_14: Williams %R\n",
    "        - CCI_20: Commodity Channel Index\n",
    "        - ATR_14, ADX_14: Average True Range y Average Directional Index\n",
    "        - PLUS_DI, MINUS_DI: Directional Indicators\n",
    "        - OBV: On-Balance Volume\n",
    "        - MFI_14: Money Flow Index\n",
    "        - BIAS_12, PSY_12, BBI: Indicadores adicionales\n",
    "        - CHO_3_10: Chaikin Oscillator\n",
    "        - MASS_25: Mass Index\n",
    "        - WVAD_24: Williams' Volume Accumulation/Distribution\n",
    "        - AR_26, BR_26, CR_26: Indicadores de momentum con volumen\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Los indicadores que requieren High/Low o Volume devuelven NaN si esos datos\n",
    "      no est√°n disponibles.\n",
    "    - Todos los valores infinitos se reemplazan por NaN y luego se eliminan las filas\n",
    "      con NaN antes de retornar.\n",
    "    - El DataFrame resultante est√° ordenado por fecha de forma ascendente.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> data = pd.read_csv(\"stock_data.csv\", index_col=\"Date\", parse_dates=True)\n",
    "    >>> features = make_tech_indicators(data, safe=True)\n",
    "    >>> print(features.columns.tolist()[:10])\n",
    "    ['Date', 'Price', 'Open', 'High', 'Low', 'Volume', 'SMA_5', 'SMA_10', ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Normalizaci√≥n de entrada ----------\n",
    "    if isinstance(data, pd.Series):\n",
    "        df = data.to_frame(name=price_col).copy()\n",
    "    else:\n",
    "        df = data.copy()\n",
    "\n",
    "    if df.index.name is None:\n",
    "        df.index.name = \"Date\"\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Asegura columnas esperadas y dtypes\n",
    "    for c in [price_col, high_col, low_col, vol_col]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if price_col not in df.columns:\n",
    "        raise ValueError(f\"Falta columna de precio '{price_col}'\")\n",
    "\n",
    "    has_hl = (high_col in df.columns) and (low_col in df.columns)\n",
    "    has_vol = vol_col in df.columns\n",
    "\n",
    "    # Alias locales\n",
    "    close = df[price_col]\n",
    "    high  = df[high_col] if has_hl else None\n",
    "    low   = df[low_col]  if has_hl else None\n",
    "    vol   = df[vol_col].replace(0, np.nan).astype(\"float64\") if has_vol else None\n",
    "\n",
    "    # ---------- Helpers internos ----------\n",
    "    ema = lambda s, span: s.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "    def true_range():\n",
    "        prev_close = close.shift(1)\n",
    "        tr1 = (high - low) if has_hl else (close - close) * np.nan\n",
    "        tr2 = (high - prev_close).abs() if has_hl else (close - prev_close).abs()\n",
    "        tr3 = (low - prev_close).abs() if has_hl else (prev_close - close).abs()\n",
    "        return pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "\n",
    "    def rsi(n=14):\n",
    "        delta = close.diff()\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "        avg_gain = gain.ewm(alpha=1/n, min_periods=n, adjust=False).mean()\n",
    "        avg_loss = loss.ewm(alpha=1/n, min_periods=n, adjust=False).mean()\n",
    "        rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "        return (100 - (100 / (1 + rs))).fillna(50.0)\n",
    "\n",
    "    def stochastic(n=14, d=3):\n",
    "        if not has_hl:\n",
    "            return pd.Series(np.nan, index=df.index), pd.Series(np.nan, index=df.index)\n",
    "        low_n = low.rolling(n).min()\n",
    "        high_n = high.rolling(n).max()\n",
    "        den = (high_n - low_n).replace(0, np.nan)\n",
    "        k = 100 * (close - low_n) / den\n",
    "        dline = k.rolling(d).mean()\n",
    "        return k, dline\n",
    "\n",
    "    def bollinger(n=20, k=2):\n",
    "        ma = close.rolling(n).mean()\n",
    "        sd = close.rolling(n).std()\n",
    "        upper, lower = ma + k*sd, ma - k*sd\n",
    "        bw = (upper - lower) / ma\n",
    "        den = (upper - lower).replace(0, np.nan)\n",
    "        pb = (close - lower) / den\n",
    "        return bw, pb\n",
    "\n",
    "    def adx_block(n=14):\n",
    "        if not has_hl:\n",
    "            nan = pd.Series(np.nan, index=df.index)\n",
    "            return nan, nan, nan, nan\n",
    "        up_move = high.diff()\n",
    "        down_move = -low.diff()\n",
    "        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)\n",
    "        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)\n",
    "        tr = true_range()\n",
    "        atr = tr.ewm(alpha=1/n, adjust=False).mean().replace(0, np.nan)\n",
    "        plus_di = 100 * pd.Series(plus_dm, index=df.index).ewm(alpha=1/n, adjust=False).mean() / atr\n",
    "        minus_di = 100 * pd.Series(minus_dm, index=df.index).ewm(alpha=1/n, adjust=False).mean() / atr\n",
    "        den = (plus_di + minus_di).replace(0, np.nan)\n",
    "        dx = 100 * (plus_di - minus_di).abs() / den\n",
    "        adx = dx.ewm(alpha=1/n, adjust=False).mean()\n",
    "        return atr, adx, plus_di, minus_di\n",
    "\n",
    "    def obv():\n",
    "        if not has_vol:\n",
    "            return pd.Series(np.nan, index=df.index)\n",
    "        return (np.sign(close.diff()).fillna(0) * vol.fillna(0)).cumsum()\n",
    "\n",
    "    def mfi(n=14):\n",
    "        if not (has_hl and has_vol):\n",
    "            return pd.Series(np.nan, index=df.index)\n",
    "        tp = (high + low + close) / 3.0\n",
    "        mf = tp * vol.fillna(0.0)\n",
    "        pos_flow = np.where(tp > tp.shift(1), mf, 0.0)\n",
    "        neg_flow = np.where(tp < tp.shift(1), mf, 0.0)\n",
    "        pos = pd.Series(pos_flow, index=df.index, dtype=\"float64\").rolling(n).sum()\n",
    "        neg = pd.Series(neg_flow, index=df.index, dtype=\"float64\").rolling(n).sum()\n",
    "        mfr = pos / neg.replace(0, np.nan)\n",
    "        return (100 - (100 / (1 + mfr))).fillna(50.0)\n",
    "\n",
    "    def cci(n=20):\n",
    "        if not has_hl:\n",
    "            return pd.Series(np.nan, index=df.index)\n",
    "        tp = (high + low + close) / 3.0\n",
    "        sma = tp.rolling(n).mean()\n",
    "        mad = (tp - sma).abs().rolling(n).mean()\n",
    "        return (tp - sma) / (0.015 * mad)\n",
    "\n",
    "    def williams_r(n=14):\n",
    "        if not has_hl:\n",
    "            return pd.Series(np.nan, index=df.index)\n",
    "        hh = high.rolling(n).max()\n",
    "        ll = low.rolling(n).min()\n",
    "        denom = (hh - ll).replace(0, np.nan)\n",
    "        return -100 * (hh - close) / denom\n",
    "\n",
    "    # ---------- C√°lculo de indicadores ----------\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    out[\"Price\"] = close.astype(\"float64\")\n",
    "\n",
    "    out[\"Open\"]   = df[\"Open\"].astype(\"float64\") if \"Open\" in df.columns else np.nan\n",
    "    out[\"High\"]   = high if has_hl else np.nan\n",
    "    out[\"Low\"]    = low if has_hl else np.nan\n",
    "    out[\"Volume\"] = df[vol_col] if has_vol else np.nan\n",
    "\n",
    "    # Tendencia\n",
    "    for n in [5, 10, 20, 50, 200]:\n",
    "        out[f\"SMA_{n}\"] = close.rolling(n).mean()\n",
    "    for n in [5, 10, 20, 50]:\n",
    "        out[f\"EMA_{n}\"] = ema(close, n)\n",
    "\n",
    "    macd = ema(close, 12) - ema(close, 26)\n",
    "    macd_sig = ema(macd, 9)\n",
    "    out[\"MACD\"]        = macd\n",
    "    out[\"MACD_signal\"] = macd_sig\n",
    "    out[\"MACD_hist\"]   = macd - macd_sig\n",
    "\n",
    "    # Momentum\n",
    "    for h in [1, 5, 10]:\n",
    "        out[f\"ROC_{h}\"] = (close - close.shift(h)) / close.shift(h)\n",
    "        out[f\"MOM_{h}\"] = close - close.shift(h)\n",
    "    out[\"RSI_14\"] = rsi(14)\n",
    "\n",
    "    # Volatilidad y bandas\n",
    "    out[\"VOL_20\"] = np.log(close / close.shift(1)).rolling(20).std()\n",
    "    bw, pb = bollinger(20, 2)\n",
    "    out[\"BB_BW\"] = bw\n",
    "    out[\"BB_PB\"] = pb\n",
    "\n",
    "    # Osciladores con H/L\n",
    "    k, d = stochastic(14, 3)\n",
    "    out[\"STOCH_K\"]  = k\n",
    "    out[\"STOCH_D\"]  = d\n",
    "    out[\"WILLR_14\"] = williams_r(14)\n",
    "    out[\"CCI_20\"]   = cci(20)\n",
    "\n",
    "    # Rango y direcci√≥n\n",
    "    atr, adx, plus_di, minus_di = adx_block(14)\n",
    "    out[\"ATR_14\"]   = atr\n",
    "    out[\"ADX_14\"]   = adx\n",
    "    out[\"PLUS_DI\"]  = plus_di\n",
    "    out[\"MINUS_DI\"] = minus_di\n",
    "\n",
    "    # Flujo / volumen\n",
    "    out[\"OBV\"]     = obv()\n",
    "    out[\"MFI_14\"]  = mfi(14)\n",
    "\n",
    "    # Extras\n",
    "    out[\"BIAS_12\"] = (close - close.rolling(12).mean()) / close.rolling(12).mean()\n",
    "    updays = (close.diff() > 0).astype(int)\n",
    "    out[\"PSY_12\"] = 100 * updays.rolling(12).mean()\n",
    "    out[\"BBI\"] = (\n",
    "        close.rolling(3).mean()\n",
    "        + close.rolling(6).mean()\n",
    "        + close.rolling(12).mean()\n",
    "        + close.rolling(24).mean()\n",
    "    ) / 4.0\n",
    "\n",
    "    # CHO (Chaikin Oscillator)\n",
    "    if has_hl and has_vol:\n",
    "        clv = ((close - low) - (high - close)) / (high - low)\n",
    "        clv = clv.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        adl = (clv * vol.fillna(0)).cumsum()\n",
    "        out[\"CHO_3_10\"] = ema(adl, 3) - ema(adl, 10)\n",
    "    else:\n",
    "        out[\"CHO_3_10\"] = np.nan\n",
    "\n",
    "    # MASS / WVAD / AR-BR / CR\n",
    "    if has_hl:\n",
    "        diff_hl = (high - low).abs()\n",
    "        e1 = diff_hl.ewm(span=9, adjust=False).mean()\n",
    "        e2 = e1.ewm(span=9, adjust=False).mean()\n",
    "        ratio = e1 / e2.replace(0, np.nan)\n",
    "        out[\"MASS_25\"] = ratio.rolling(25).sum()\n",
    "    else:\n",
    "        out[\"MASS_25\"] = np.nan\n",
    "\n",
    "    if has_hl and has_vol:\n",
    "        rng = (high - low).replace(0, np.nan)\n",
    "        out[\"WVAD_24\"] = (((close - df.get(\"Open\", close)) / rng) * vol).rolling(24).sum()\n",
    "\n",
    "        ar_num = (high - df.get(\"Open\", close)).rolling(26).sum()\n",
    "        ar_den = (df.get(\"Open\", close) - low).rolling(26).sum().replace(0, np.nan)\n",
    "        out[\"AR_26\"] = 100 * ar_num / ar_den\n",
    "\n",
    "        cp = close.shift(1)\n",
    "        br_num = (high - cp).rolling(26).sum()\n",
    "        br_den = (cp - low).rolling(26).sum().replace(0, np.nan)\n",
    "        out[\"BR_26\"] = 100 * br_num / br_den\n",
    "\n",
    "        mid   = (high + low + 2*close) / 4\n",
    "        mid_y = mid.shift(1)\n",
    "        up    = (high - mid_y).clip(lower=0)\n",
    "        down  = (mid_y - low).clip(lower=0)\n",
    "        out[\"CR_26\"] = 100 * up.rolling(26).sum() / down.rolling(26).sum().replace(0, np.nan)\n",
    "    else:\n",
    "        out[\"WVAD_24\"] = np.nan\n",
    "        out[\"AR_26\"]   = np.nan\n",
    "        out[\"BR_26\"]   = np.nan\n",
    "        out[\"CR_26\"]   = np.nan\n",
    "\n",
    "    # ---------- Anti-fuga ----------\n",
    "    if safe:\n",
    "        feat_cols = [c for c in out.columns if c != \"Price\"]\n",
    "        out[feat_cols] = out[feat_cols].shift(1)\n",
    "\n",
    "    # ---------- Limpieza ----------\n",
    "    out = out.astype(\"float64\")\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    out = out.dropna().copy()\n",
    "\n",
    "    if reset_index:\n",
    "        out = out.rename_axis(\"Date\").reset_index()\n",
    "\n",
    "    return out\n",
    "\n",
    "@dataclass\n",
    "class SplitDates:\n",
    "    \"\"\"\n",
    "    Almacena las fechas de corte para dividir datos temporales en train, validation y test.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    train_end : str\n",
    "        Fecha de fin del conjunto de entrenamiento (inclusive), formato \"YYYY-MM-DD\".\n",
    "    val_end : str\n",
    "        Fecha de fin del conjunto de validaci√≥n (inclusive), formato \"YYYY-MM-DD\".\n",
    "    test_end : Optional[str], default=None\n",
    "        Fecha de fin del conjunto de test (inclusive), formato \"YYYY-MM-DD\".\n",
    "        Si es None, el conjunto de test incluye todo desde val_end hasta el final.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> splits = SplitDates(\n",
    "    ...     train_end=\"2020-12-31\",\n",
    "    ...     val_end=\"2021-06-30\",\n",
    "    ...     test_end=\"2021-12-31\"\n",
    "    ... )\n",
    "    \"\"\"\n",
    "    train_end: str\n",
    "    val_end: str\n",
    "    test_end: Optional[str] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_ratios(cls, X_y: pd.DataFrame, train_ratio: float, val_ratio: float):\n",
    "        \"\"\"\n",
    "        Crea splits basados en proporciones del √≠ndice temporal.\n",
    "        \n",
    "        Divide los datos temporalmente seg√∫n las proporciones especificadas:\n",
    "        - Train: desde el inicio hasta train_ratio del total\n",
    "        - Validation: desde train_ratio hasta (train_ratio + val_ratio) del total\n",
    "        - Test: desde (train_ratio + val_ratio) hasta el final\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_y : pd.DataFrame\n",
    "            DataFrame con √≠ndice DatetimeIndex ordenado de forma ascendente.\n",
    "        train_ratio : float\n",
    "            Proporci√≥n de datos para entrenamiento (0.0 a 1.0).\n",
    "            Ejemplo: 0.7 significa 70% de los datos.\n",
    "        val_ratio : float\n",
    "            Proporci√≥n de datos para validaci√≥n (0.0 a 1.0).\n",
    "            Ejemplo: 0.1 significa 10% de los datos.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        SplitDates\n",
    "            Instancia de SplitDates con las fechas calculadas.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        - El √≠ndice de X_y DEBE ser un DatetimeIndex ordenado.\n",
    "        - train_ratio + val_ratio debe ser <= 1.0\n",
    "        - Si train_ratio + val_ratio = 1.0, test_end ser√° None.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        >>> X_y = pd.DataFrame(index=pd.date_range(\"2020-01-01\", \"2021-12-31\", freq=\"D\"))\n",
    "        >>> splits = SplitDates.from_ratios(X_y, train_ratio=0.7, val_ratio=0.1)\n",
    "        >>> print(splits.train_end, splits.val_end)\n",
    "        \"\"\"\n",
    "        idx = X_y.index\n",
    "        n = len(idx)\n",
    "        \n",
    "        # Posiciones en enteros\n",
    "        \n",
    "        pos_train_end = int(n*train_ratio) \n",
    "        pos_val_end = int(n*(train_ratio + val_ratio))\n",
    "        \n",
    "        pos_train_end = min(max(pos_train_end,0),n-1)\n",
    "        pos_val_end = min(max(pos_val_end,0),n-1)\n",
    "        \n",
    "        # Convertir posiciones a fechas\n",
    "        train_end_date = idx[pos_train_end].strftime(\"%Y-%m-%d\")\n",
    "        val_end_date = idx[pos_val_end].strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        if pos_val_end == n-1:\n",
    "            test_end_date = None\n",
    "        else: \n",
    "            test_end_date = idx[-1].strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "        return cls(\n",
    "                   train_end=train_end_date,\n",
    "                   val_end=val_end_date,\n",
    "                   test_end=test_end_date\n",
    "        )\n",
    "\n",
    "\n",
    "def build_xy(features_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Construye las matrices X (features) e y (target) a partir de features t√©cnicos.\n",
    "    \n",
    "    El target y es el precio del siguiente per√≠odo (Price_next = Price(t+1)),\n",
    "    mientras que X contiene todos los features disponibles en el per√≠odo actual.\n",
    "    Elimina autom√°ticamente columnas constantes que no aportan informaci√≥n.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos. Debe contener una columna \"Price\" y\n",
    "        opcionalmente una columna \"Date\". Si tiene \"Date\", se usa como √≠ndice.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[pd.DataFrame, pd.Series]\n",
    "        Tupla (X, y) donde:\n",
    "        - X: DataFrame con todas las columnas de features (incluyendo Price).\n",
    "              El √≠ndice es DatetimeIndex ordenado.\n",
    "        - y: Series con el precio del siguiente per√≠odo (Price_next).\n",
    "              El √≠ndice coincide con X (excepto la √∫ltima fila que se elimina).\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Elimina autom√°ticamente columnas constantes (con un solo valor √∫nico).\n",
    "    - Elimina filas con NaN resultantes del shift.\n",
    "    - X e y tienen √≠ndices alineados.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> features = make_tech_indicators(data)\n",
    "    >>> X, y = build_xy(features)\n",
    "    >>> print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    >>> print(f\"Target: precio del d√≠a siguiente\")\n",
    "    \"\"\"\n",
    "    df = features_df.copy()\n",
    "    if \"Date\" in df.columns: # Hacer de √≠ndice si est√° como columna\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df = df.set_index(\"Date\").sort_index()\n",
    "\n",
    "    df[\"Price_next\"] = df[\"Price\"].shift(-1)  # Price(t+1)\n",
    "    df = df.dropna()\n",
    "\n",
    "    y = df[\"Price_next\"].astype(float)\n",
    "    X = df.drop(columns=[\"Price_next\"])\n",
    "\n",
    "    const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1] # columnas constantes\n",
    "    if const_cols:\n",
    "        X = X.drop(columns=const_cols)\n",
    "\n",
    "    assert X.index.equals(y.index)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def time_splits(\n",
    "    X: pd.DataFrame, \n",
    "    y: pd.Series, \n",
    "    dates: SplitDates\n",
    ") -> tuple[tuple[pd.DataFrame, pd.Series], tuple[pd.DataFrame, pd.Series], tuple[pd.DataFrame, pd.Series]]:\n",
    "    \"\"\"\n",
    "    Divide los datos en conjuntos de train, validation y test seg√∫n fechas especificadas.\n",
    "    \n",
    "    Realiza una divisi√≥n temporal estricta respetando el orden cronol√≥gico.\n",
    "    No hay solapamiento entre los conjuntos y se mantiene el orden temporal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        DataFrame con features. Debe tener un √≠ndice DatetimeIndex.\n",
    "    y : pd.Series\n",
    "        Series con el target. Debe tener el mismo √≠ndice que X.\n",
    "    dates : SplitDates\n",
    "        Objeto con las fechas de corte para train, validation y test.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tupla de tres elementos, cada uno es una tupla (X_subset, y_subset):\n",
    "        - ((X_train, y_train), (X_val, y_val), (X_test, y_test))\n",
    "        \n",
    "        Donde:\n",
    "        - X_train, y_train: Datos hasta dates.train_end (inclusive)\n",
    "        - X_val, y_val: Datos desde dates.train_end (exclusive) hasta dates.val_end (inclusive)\n",
    "        - X_test, y_test: Datos desde dates.val_end (exclusive) hasta dates.test_end\n",
    "          (o hasta el final si dates.test_end es None)\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Las divisiones son inclusivas en el extremo superior seg√∫n las fechas especificadas.\n",
    "    - No hay mezcla temporal entre conjuntos.\n",
    "    - X e y deben tener √≠ndices alineados.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> splits = SplitDates(train_end=\"2020-12-31\", val_end=\"2021-06-30\")\n",
    "    >>> (X_train, y_train), (X_val, y_val), (X_test, y_test) = time_splits(X, y, splits)\n",
    "    >>> print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "    \"\"\"\n",
    "    idx = X.index\n",
    "    train = idx <= pd.to_datetime(dates.train_end)\n",
    "    val   = (idx > pd.to_datetime(dates.train_end)) & (idx <= pd.to_datetime(dates.val_end))\n",
    "    test  = idx > pd.to_datetime(dates.val_end) if dates.test_end is None else (\n",
    "            (idx > pd.to_datetime(dates.val_end)) & (idx <= pd.to_datetime(dates.test_end)))\n",
    "    return (X.loc[train], y.loc[train]), (X.loc[val], y.loc[val]), (X.loc[test], y.loc[test])\n",
    "\n",
    "\n",
    "class TimeScaler:\n",
    "    \"\"\"\n",
    "    Escalador MinMax para features X que respeta el orden temporal.\n",
    "    \n",
    "    Aplica escalado MinMax solo sobre datos de entrenamiento para evitar\n",
    "    fuga de datos temporal. El fit se hace √∫nicamente con datos de train,\n",
    "    y luego se aplica la misma transformaci√≥n a validation y test.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    scaler : MinMaxScaler\n",
    "        Escalador de sklearn que realiza la transformaci√≥n MinMax.\n",
    "    cols_ : list[str]\n",
    "        Lista de columnas que se usaron durante el fit. Se guarda para\n",
    "        asegurar consistencia en transformaciones posteriores.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> scaler = TimeScaler(feature_range=(0, 1))\n",
    "    >>> scaler.fit(X_train)\n",
    "    >>> X_train_scaled = scaler.transform(X_train)\n",
    "    >>> X_val_scaled = scaler.transform(X_val)\n",
    "    >>> X_test_scaled = scaler.transform(X_test)\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_range=(0, 1)):\n",
    "        \"\"\"\n",
    "        Inicializa el escalador.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_range : tuple, default=(0, 1)\n",
    "            Rango deseado para los datos escalados (min, max).\n",
    "        \"\"\"\n",
    "        self.scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        self.cols_: list[str] = []\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame) -> \"TimeScaler\":\n",
    "        \"\"\"\n",
    "        Ajusta el escalador usando solo datos de entrenamiento.\n",
    "        \n",
    "        Calcula los par√°metros de escalado (min, max) a partir de X_train\n",
    "        y guarda el orden de las columnas para transformaciones futuras.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : pd.DataFrame\n",
    "            DataFrame con features de entrenamiento. Debe tener columnas nombradas.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        TimeScaler\n",
    "            Retorna self para permitir method chaining.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        - Los par√°metros calculados se usan para todas las transformaciones\n",
    "          posteriores (val, test), evitando fuga de datos temporal.\n",
    "        \"\"\"\n",
    "        self.scaler.fit(X_train.values)\n",
    "        self.cols_ = list(X_train.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transforma los datos usando los par√°metros calculados en fit.\n",
    "        \n",
    "        Aplica la misma transformaci√≥n MinMax calculada en fit a nuevos datos.\n",
    "        Verifica que las columnas coincidan con las usadas durante el fit.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            DataFrame con features a transformar. Debe contener las mismas\n",
    "            columnas que se usaron en fit (puede tener columnas extra que\n",
    "            se ignoran).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array numpy con los datos escalados. Shape: (n_samples, n_features).\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        AssertionError\n",
    "            Si faltan columnas que se usaron durante el fit.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        - Si X tiene columnas extra, se muestran un aviso pero no se lanza error.\n",
    "        - Las columnas se reordenan seg√∫n el orden guardado en fit.\n",
    "        \"\"\"\n",
    "        missing = [c for c in self.cols_ if c not in X.columns]\n",
    "        extra   = [c for c in X.columns if c not in self.cols_]\n",
    "        assert not missing, f\"Faltan columnas para transformar: {missing}\"\n",
    "        if extra:\n",
    "            print(f\"[AVISO] Columnas extra ignoradas en transform: {extra}\")\n",
    "        X2 = X[self.cols_].values\n",
    "        return self.scaler.transform(X2)\n",
    "\n",
    "\n",
    "class TimeScalerY:\n",
    "    \"\"\"\n",
    "    Escalador MinMax para el target y que respeta el orden temporal.\n",
    "    \n",
    "    Similar a TimeScaler pero dise√±ado espec√≠ficamente para el target (y).\n",
    "    Permite transformar e invertir la transformaci√≥n para recuperar valores\n",
    "    en escala original.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    scaler : MinMaxScaler\n",
    "        Escalador de sklearn que realiza la transformaci√≥n MinMax.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> scaler_y = TimeScalerY()\n",
    "    >>> scaler_y.fit(y_train)\n",
    "    >>> y_train_scaled = scaler_y.transform(y_train)\n",
    "    >>> y_pred_scaled = model.predict(X_test)\n",
    "    >>> y_pred = scaler_y.inverse(y_pred_scaled)  # Volver a escala original\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el escalador con rango por defecto (0, 1).\"\"\"\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def fit(self, y_train: np.ndarray) -> \"TimeScalerY\":\n",
    "        \"\"\"\n",
    "        Ajusta el escalador usando solo datos de entrenamiento del target.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_train : np.ndarray\n",
    "            Array 1D con valores del target de entrenamiento.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        TimeScalerY\n",
    "            Retorna self para permitir method chaining.\n",
    "        \"\"\"\n",
    "        self.scaler.fit(y_train.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Transforma el target a escala normalizada.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.ndarray\n",
    "            Array 1D con valores del target a escalar.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array 1D con valores escalados en rango [0, 1] (por defecto).\n",
    "        \"\"\"\n",
    "        return self.scaler.transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "    def inverse(self, y_scaled: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Invierte la transformaci√≥n para recuperar valores en escala original.\n",
    "        \n",
    "        √ötil para convertir predicciones escaladas de vuelta a la escala\n",
    "        original de precios (por ejemplo, d√≥lares).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_scaled : np.ndarray\n",
    "            Array 1D con valores escalados (en rango [0, 1] por defecto).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Array 1D con valores en escala original.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        >>> y_pred_scaled = model.predict(X_test)  # Predicciones en [0, 1]\n",
    "        >>> y_pred_real = scaler_y.inverse(y_pred_scaled)  # Predicciones en d√≥lares\n",
    "        \"\"\"\n",
    "        return self.scaler.inverse_transform(y_scaled.reshape(-1,1)).flatten()\n",
    "\n",
    "\n",
    "def make_sequences(\n",
    "    X_arr: np.ndarray,\n",
    "    y_arr: np.ndarray,\n",
    "    dates_arr: np.ndarray,\n",
    "    lookback: int = 5,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Construye secuencias temporales (ventanas deslizantes) para modelos de series temporales.\n",
    "    \n",
    "    Crea ventanas de lookback per√≠odos consecutivos para predecir el valor del target\n",
    "    en el per√≠odo actual. Cada muestra usa informaci√≥n de los √∫ltimos 'lookback' per√≠odos\n",
    "    para predecir el valor en t.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_arr : np.ndarray\n",
    "        Array 2D con features, shape (n_samples, n_features).\n",
    "        Debe estar ordenado temporalmente.\n",
    "    y_arr : np.ndarray\n",
    "        Array 1D con valores del target, shape (n_samples,).\n",
    "        Debe estar alineado con X_arr.\n",
    "    dates_arr : np.ndarray\n",
    "        Array 1D con fechas correspondientes a cada muestra, shape (n_samples,).\n",
    "    lookback : int, default=5   \n",
    "        N√∫mero de per√≠odos hacia atr√°s a incluir en cada ventana.\n",
    "        Cada secuencia tendr√° lookback muestras consecutivas.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        Tupla (X_seq, y_seq, d_seq) donde:\n",
    "        - X_seq: Array 3D con secuencias, shape (n_sequences, lookback, n_features).\n",
    "                 Cada fila es una ventana de lookback per√≠odos consecutivos.\n",
    "        - y_seq: Array 1D con targets, shape (n_sequences,).\n",
    "                 y_seq[i] corresponde al target en el per√≠odo final de X_seq[i].\n",
    "        - d_seq: Array 1D con fechas, shape (n_sequences,).\n",
    "                 d_seq[i] es la fecha del per√≠odo final de la secuencia X_seq[i].\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - El n√∫mero de secuencias resultantes es: n_samples - lookback + 1\n",
    "    - La primera secuencia usa √≠ndices [0:lookback] para predecir y[lookback-1]\n",
    "    - La √∫ltima secuencia usa √≠ndices [n-lookback:n] para predecir y[n-1]\n",
    "    - Todas las secuencias tienen exactamente lookback per√≠odos.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> X_arr = np.random.rand(100, 10)  # 100 muestras, 10 features\n",
    "    >>> y_arr = np.random.rand(100)\n",
    "    >>> dates = pd.date_range(\"2020-01-01\", periods=100)\n",
    "    >>> X_seq, y_seq, d_seq = make_sequences(X_arr, y_arr, dates, lookback=5)\n",
    "    >>> print(f\"X_seq shape: {X_seq.shape}\")  # (96, 5, 10)\n",
    "    >>> print(f\"y_seq shape: {y_seq.shape}\")  # (96,)\n",
    "    \"\"\"\n",
    "    n = len(y_arr)\n",
    "    X_seq, y_seq, d_seq = [], [], []\n",
    "\n",
    "    for t in range(lookback - 1, n):\n",
    "        X_seq.append(X_arr[t - lookback + 1:t + 1, :])\n",
    "        y_seq.append(y_arr[t])\n",
    "        d_seq.append(dates_arr[t])\n",
    "\n",
    "    return (\n",
    "        np.array(X_seq, dtype=np.float32),\n",
    "        np.array(y_seq, dtype=np.float32),\n",
    "        np.array(d_seq),\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LSTMPrepConfig:\n",
    "    \"\"\"\n",
    "    Configuraci√≥n para preparar datos para modelos LSTM.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    lookback : int, default=5\n",
    "        N√∫mero de per√≠odos hacia atr√°s a incluir en cada secuencia.\n",
    "    horizon : int, default=1\n",
    "        Horizonte de predicci√≥n (solo informativo, no se usa en el c√≥digo).\n",
    "    selected_features : Optional[Sequence[str]], default=None\n",
    "        Lista de nombres de features a usar. Si None, se usan todos los features.\n",
    "    \"\"\"\n",
    "    lookback: int = 5\n",
    "    horizon: int = 1\n",
    "    selected_features: Optional[Sequence[str]] = None\n",
    "\n",
    "\n",
    "def prepare_lstm_data(\n",
    "    features_df: pd.DataFrame,\n",
    "    split_dates: SplitDates,\n",
    "    cfg: LSTMPrepConfig = LSTMPrepConfig(),\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Prepara datos escalados y secuenciados para modelos LSTM o tabulares.\n",
    "    \n",
    "    Realiza el pipeline completo de preparaci√≥n:\n",
    "    1. Construye X e y desde features\n",
    "    2. Selecciona features si se especifica\n",
    "    3. Divide en train/val/test temporalmente\n",
    "    4. Escala X e y usando solo datos de train\n",
    "    5. Construye secuencias temporales (ventanas)\n",
    "    6. Divide las secuencias en train/val/test\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos generados por make_tech_indicators.\n",
    "    split_dates : SplitDates\n",
    "        Objeto con fechas de corte para train, validation y test.\n",
    "    cfg : LSTMPrepConfig, default=LSTMPrepConfig()\n",
    "        Configuraci√≥n con lookback, horizon y features seleccionados.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con las siguientes claves:\n",
    "        - \"X_train\", \"X_val\", \"X_test\": Arrays 3D con secuencias, shape (n_samples, lookback, n_features)\n",
    "        - \"y_train\", \"y_val\", \"y_test\": Arrays 1D con targets escalados\n",
    "        - \"scaler_x\": Instancia de TimeScaler ajustada\n",
    "        - \"scaler_y\": Instancia de TimeScalerY ajustada\n",
    "        - \"feature_cols\": Lista de nombres de features usados\n",
    "        - \"lookback\": Valor de lookback usado\n",
    "        - \"horizon\": Horizonte de predicci√≥n (1)\n",
    "        - \"dates_seq\": Array con fechas correspondientes a cada secuencia\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - El escalado se hace solo con datos de train para evitar fuga de datos.\n",
    "    - Las secuencias se construyen antes de dividir, luego se filtran por fecha.\n",
    "    - Los datos est√°n en escala normalizada [0, 1] (por defecto).\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> features = make_tech_indicators(data)\n",
    "    >>> splits = SplitDates.from_ratios(X_y, train_ratio=0.7, val_ratio=0.1)\n",
    "    >>> cfg = LSTMPrepConfig(lookback=5, selected_features=[\"RSI_14\", \"MACD\"])\n",
    "    >>> prep = prepare_lstm_data(features, splits, cfg)\n",
    "    >>> print(f\"X_train shape: {prep['X_train'].shape}\")  # (n, 5, 2)\n",
    "    \"\"\"\n",
    "    X, y = build_xy(features_df)\n",
    "\n",
    "    if cfg.selected_features is not None:\n",
    "        keep = [c for c in cfg.selected_features if c in X.columns]\n",
    "        X = X[keep]\n",
    "        assert list(X.columns) == keep\n",
    "\n",
    "    (X_tr, y_tr), _, _ = time_splits(X, y, split_dates) # Solo X_tr, y_tr para fit\n",
    "\n",
    "    scaler_x = TimeScaler().fit(X_tr) # Se usa solo X_tr para fit, as√≠ no hay fuga\n",
    "    X_all_scaled = scaler_x.transform(X)\n",
    "\n",
    "    y_all    = y.values.astype(np.float32)\n",
    "    y_tr_arr = y_tr.values.astype(np.float32)\n",
    "\n",
    "    scaler_y      = TimeScalerY().fit(y_tr_arr)  # Solo y_tr para fit, as√≠ no hay fuga\n",
    "    y_all_scaled  = scaler_y.transform(y_all)\n",
    "    dates_all     = X.index.to_numpy()\n",
    "\n",
    "    X_seq, y_seq, d_seq = make_sequences(\n",
    "        X_all_scaled,\n",
    "        y_all_scaled,\n",
    "        dates_all,\n",
    "        lookback=cfg.lookback,\n",
    "    )\n",
    "\n",
    "    train_end_dt = pd.to_datetime(split_dates.train_end)\n",
    "    val_end_dt   = pd.to_datetime(split_dates.val_end)\n",
    "    test_end_dt  = pd.to_datetime(split_dates.test_end) if split_dates.test_end is not None else None\n",
    "\n",
    "    train_mask = d_seq <= train_end_dt\n",
    "    val_mask   = (d_seq > train_end_dt) & (d_seq <= val_end_dt)\n",
    "    test_mask  = d_seq > val_end_dt if test_end_dt is None else (\n",
    "                 (d_seq > val_end_dt) & (d_seq <= test_end_dt))\n",
    "\n",
    "    Xtr_seq, ytr_seq = X_seq[train_mask], y_seq[train_mask]\n",
    "    Xva_seq, yva_seq = X_seq[val_mask], y_seq[val_mask]\n",
    "    Xte_seq, yte_seq = X_seq[test_mask], y_seq[test_mask]\n",
    "\n",
    "    return {\n",
    "        \"X_train\": Xtr_seq,\n",
    "        \"y_train\": ytr_seq,\n",
    "        \"X_val\":   Xva_seq,\n",
    "        \"y_val\":   yva_seq,\n",
    "        \"X_test\":  Xte_seq,\n",
    "        \"y_test\":  yte_seq,\n",
    "        \"scaler_x\":  scaler_x,\n",
    "        \"scaler_y\":  scaler_y,\n",
    "        \"feature_cols\": list(X.columns),\n",
    "        \"lookback\": cfg.lookback,\n",
    "        \"horizon\": 1,\n",
    "        \"dates_seq\": d_seq,\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_tabular_from_lstm_prep(\n",
    "    prep_dict: dict\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convierte secuencias 3D (ventanas temporales) a matrices 2D para modelos tabulares.\n",
    "    \n",
    "    Aplana las ventanas temporales en vectores unidimensionales, permitiendo\n",
    "    usar modelos de sklearn (RandomForest, SVR, etc.) que requieren entrada 2D.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prep_dict : dict\n",
    "        Diccionario retornado por prepare_lstm_data con las claves:\n",
    "        - \"X_train\", \"X_val\", \"X_test\": Arrays 3D shape (n, lookback, n_features)\n",
    "        - \"y_train\", \"y_val\", \"y_test\": Arrays 1D\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tupla (Xtr, ytr, Xva, yva, Xte, yte) donde:\n",
    "        - Xtr, Xva, Xte: Arrays 2D shape (n_samples, lookback * n_features)\n",
    "          Cada fila es una ventana aplanada.\n",
    "        - ytr, yva, yte: Arrays 1D con targets (sin cambios)\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - La transformaci√≥n es: (n, lookback, n_features) -> (n, lookback * n_features)\n",
    "    - √ötil para usar modelos de sklearn con datos secuenciados sin perder\n",
    "      la informaci√≥n temporal (se incluye como features adicionales).\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> prep = prepare_lstm_data(features, splits)\n",
    "    >>> Xtr, ytr, Xva, yva, Xte, yte = prepare_tabular_from_lstm_prep(prep)\n",
    "    >>> print(f\"Xtr shape: {Xtr.shape}\")  # (n, lookback * n_features)\n",
    "    >>> rf = RandomForestRegressor().fit(Xtr, ytr)\n",
    "    \"\"\"\n",
    "    def _flat(Xseq):\n",
    "        n, L, f = Xseq.shape\n",
    "        return Xseq.reshape(n, L * f)\n",
    "\n",
    "    Xtr = _flat(prep_dict[\"X_train\"])\n",
    "    Xva = _flat(prep_dict[\"X_val\"])\n",
    "    Xte = _flat(prep_dict[\"X_test\"])\n",
    "    ytr = prep_dict[\"y_train\"]\n",
    "    yva = prep_dict[\"y_val\"]\n",
    "    yte = prep_dict[\"y_test\"]\n",
    "    return Xtr, ytr, Xva, yva, Xte, yte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8174f77",
   "metadata": {},
   "source": [
    "\n",
    "| **Indicador** | **F√≥rmula** | **Descripci√≥n / Interpretaci√≥n** |\n",
    "|----------------|-------------|----------------------------------|\n",
    "| **SMA (Simple Moving Average)** | $ SMA_t = \\frac{1}{n}\\sum_{i=0}^{n-1} P_{t-i} $ | Promedio simple de precios. Suaviza ruido y muestra tendencia general. |\n",
    "| **EMA (Exponential Moving Average)** | $ EMA_t = \\alpha P_t + (1-\\alpha) EMA_{t-1}, \\ \\alpha = \\frac{2}{n+1} $ | Promedio ponderado que da m√°s importancia a precios recientes. |\n",
    "| **MACD (Moving Average Convergence Divergence)** | $ MACD_t = EMA_{12} - EMA_{26}, \\ Signal_t = EMA_9(MACD_t) $ | Mide convergencia/divergencia entre medias m√≥viles; cruces indican cambios de tendencia. |\n",
    "| **ROC (Rate of Change)** | $ ROC_t = \\frac{P_t - P_{t-n}}{P_{t-n}} $ | Tasa de cambio porcentual del precio; mide momentum relativo. |\n",
    "| **MOM (Momentum)** | $ MOM_t = P_t - P_{t-n} $ | Diferencia absoluta del precio en $n$ periodos; fuerza del movimiento. |\n",
    "| **RSI (Relative Strength Index)** | $ RSI_t = 100 - \\frac{100}{1 + RS}, \\ RS = \\frac{\\text{promedio ganancias}}{\\text{promedio p√©rdidas}} $ | Oscilador 0‚Äì100; sobrecompra >70, sobreventa <30. |\n",
    "| **PSY (Psychological Line)** | $ PSY_t = 100 \\times \\frac{\\#(P_t > P_{t-1})}{n} $ | Porcentaje de d√≠as con cierre al alza; mide sentimiento del mercado. |\n",
    "| **VOL (Volatilidad 20d)** | $ VOL_t = \\sigma\\left(\\ln\\frac{P_t}{P_{t-1}}\\right)_{20} $ | Desviaci√≥n est√°ndar de los retornos logar√≠tmicos a 20 d√≠as. |\n",
    "| **Bollinger Bands (BW, PB)** | $ BW = \\frac{U-L}{MA}, \\ PB = \\frac{P-L}{U-L}, \\ U=MA+k\\sigma, L=MA-k\\sigma $ | Ancho de banda (volatilidad) y posici√≥n del precio dentro del canal. |\n",
    "| **Stochastic Oscillator (K, D)** | $ \\%K = 100\\frac{P - L_n}{H_n - L_n}, \\%D = SMA_3(\\%K) $ | Relaci√≥n del cierre actual con el rango de precios reciente; detecta extremos. |\n",
    "| **Williams %R** | $ \\%R = -100\\frac{H_n - P}{H_n - L_n} $ | Similar al Stochastic; sobrecompra/sobreventa. |\n",
    "| **CCI (Commodity Channel Index)** | $ CCI = \\frac{TP - SMA(TP)}{0.015 \\times MAD(TP)}, \\ TP=\\frac{H+L+C}{3} $ | Mide la desviaci√≥n del precio respecto a su promedio t√≠pico. |\n",
    "| **ATR (Average True Range)** | $ ATR = EMA(TR), \\ TR=\\max(H-L, |H-C_{t-1}|, |L-C_{t-1}|) $ | Volatilidad ‚Äúreal‚Äù considerando huecos (gaps). |\n",
    "| **ADX (Average Directional Index)** | $ ADX = EMA\\left(100\\frac{|+DI - -DI|}{+DI + -DI}\\right) $ | Mide la fuerza de la tendencia (sin direcci√≥n). |\n",
    "| **+DI / -DI (Directional Indicators)** | $ +DI = 100\\frac{EMA(+DM)}{ATR}, \\ -DI = 100\\frac{EMA(-DM)}{ATR} $ | Miden presi√≥n compradora (+DI) o vendedora (-DI). |\n",
    "| **OBV (On-Balance Volume)** | $ OBV_t = OBV_{t-1} + \\text{sign}(P_t - P_{t-1})V_t $ | Acumula volumen seg√∫n direcci√≥n del precio; confirma tendencias. |\n",
    "| **MFI (Money Flow Index)** | $ MFI = 100 - \\frac{100}{1 + \\frac{\\sum MF^+}{\\sum MF^-}} $, $ MF=TP\\times V $ | RSI ponderado por volumen; mide flujo de dinero. |\n",
    "| **BIAS** | $ BIAS = \\frac{P - SMA_n(P)}{SMA_n(P)} $ | Desviaci√≥n porcentual del precio respecto a su media. |\n",
    "| **BBI (Bull and Bear Index)** | $ BBI = \\frac{SMA_3 + SMA_6 + SMA_{12} + SMA_{24}}{4} $ | Promedio de 4 SMAs; muestra tendencia de medio plazo. |\n",
    "| **CHO (Chaikin Oscillator)** | $ CHO = EMA_3(ADL) - EMA_{10}(ADL), \\ ADL = \\sum (CLV \\times V) $ | Detecta acumulaci√≥n/distribuci√≥n mediante volumen y rango. |\n",
    "| **MASS Index** | $ MASS = \\sum_{i=0}^{25} \\frac{EMA_9(H-L)}{EMA_9(EMA_9(H-L))} $ | Detecta posibles reversiones de tendencia por expansi√≥n del rango. |\n",
    "| **WVAD (Williams Variable A/D)** | $ WVAD = \\sum \\frac{(C - O)}{H - L} \\times V $ | Mide presi√≥n de compra/venta combinando rango y volumen. |\n",
    "| **AR** | $ AR = 100 \\frac{\\sum(H - O)}{\\sum(O - L)} $ | Eval√∫a fuerza interna de compradores vs. vendedores. |\n",
    "| **BR** | $ BR = 100 \\frac{\\sum(H - C_{t-1})}{\\sum(C_{t-1} - L)} $ | Eval√∫a fuerza externa de reacci√≥n del mercado. |\n",
    "| **CR (Energy Index)** | $ CR = 100 \\frac{\\sum(H - MID_{t-1})}{\\sum(MID_{t-1} - L)} $, $ MID=\\frac{H+L+2C}{4} $ | Variante que mide presi√≥n compradora mediante media desplazada. |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Notas\n",
    "- Todos los indicadores se **desplazan 1 paso (`shift(1)`)** cuando `safe=True`, para evitar fuga temporal.  \n",
    "- Los que requieren `High`, `Low` o `Volume` devuelven `NaN` si faltan esas columnas.  \n",
    "- Los primeros valores se pierden por ventanas de c√°lculo (`rolling`, `EMA`).  \n",
    "- Todos los resultados son `float64` y listos para modelado o an√°lisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75579b0d",
   "metadata": {},
   "source": [
    "## Dise√±o de Algoritmo Gen√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_subset_TS(X: pd.DataFrame, y: pd.Series, mask: np.ndarray, n_splits: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    Eval√∫a un subset de features usando TimeSeriesSplit y Ridge como funci√≥n de fitness para el GA.\n",
    "    \n",
    "    Calcula el R¬≤ medio mediante validaci√≥n cruzada temporal (TimeSeriesSplit) usando\n",
    "    un modelo Ridge sobre el subset de features seleccionado por la m√°scara.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        DataFrame con todas las features disponibles.\n",
    "    y : pd.Series\n",
    "        Series con el target.\n",
    "    mask : np.ndarray\n",
    "        Array booleano 1D indicando qu√© features incluir (True) o excluir (False).\n",
    "        Debe tener la misma longitud que el n√∫mero de columnas en X.\n",
    "    n_splits : int, default=5\n",
    "        N√∫mero de divisiones para TimeSeriesSplit.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        R¬≤ medio del subset de features. Retorna -1e9 si:\n",
    "        - El subset tiene menos de 3 features\n",
    "        - No se pudo calcular el R¬≤\n",
    "        - El R¬≤ no es finito\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Usa StandardScaler + Ridge(alpha=1.0) como modelo base.\n",
    "    - TimeSeriesSplit respeta el orden temporal de los datos.\n",
    "    - Esta funci√≥n se usa como fitness en el algoritmo gen√©tico.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> mask = np.array([True, False, True, True, False])\n",
    "    >>> fitness = evaluar_subset_TS(X, y, mask, n_splits=5)\n",
    "    >>> print(f\"Fitness: {fitness}\")\n",
    "    \"\"\"\n",
    "    sel_cols = X.columns[mask]\n",
    "    if len(sel_cols) < 3:\n",
    "        return -1e9\n",
    "\n",
    "    Xs = X[sel_cols].values\n",
    "    ys = y.values\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    modelo = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"reg\", Ridge(alpha=1.0))\n",
    "    ])\n",
    "\n",
    "    r2_list = []\n",
    "    for tr_idx, te_idx in tscv.split(Xs):\n",
    "        Xtr, Xte = Xs[tr_idx], Xs[te_idx]\n",
    "        ytr, yte = ys[tr_idx], ys[te_idx]\n",
    "        modelo.fit(Xtr, ytr)\n",
    "        pr = modelo.predict(Xte)\n",
    "        r2_list.append(r2_score(yte, pr))\n",
    "\n",
    "    if not r2_list:\n",
    "        return -1e9\n",
    "\n",
    "    r2_mean = float(np.mean(r2_list))\n",
    "    if not np.isfinite(r2_mean):\n",
    "        r2_mean = -1e9\n",
    "    return r2_mean\n",
    "\n",
    "\n",
    "def _multipoint_crossover(p1: np.ndarray, p2: np.ndarray, n_points=2):\n",
    "    L = len(p1)\n",
    "    if L < 2:\n",
    "        return p1.copy(), p2.copy()\n",
    "    pts = np.sort(np.random.choice(np.arange(1, L), size=min(n_points, max(1, L-1)), replace=False))\n",
    "    child1, child2 = p1.copy(), p2.copy()\n",
    "    swap = False\n",
    "    last = 0\n",
    "    for pt in list(pts) + [L]:\n",
    "        if swap:\n",
    "            child1[last:pt], child2[last:pt] = p2[last:pt], p1[last:pt]\n",
    "        last = pt\n",
    "        swap = not swap\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "def _bitflip_mutation(ind: np.ndarray, p=0.003):\n",
    "    flips = np.random.rand(ind.size) < p\n",
    "    ind[flips] = ~ind[flips]\n",
    "    return ind\n",
    "\n",
    "\n",
    "def _ensure_min_features(ind: np.ndarray, kmin=3):\n",
    "    on = ind.sum()\n",
    "    if on < kmin:\n",
    "        idx0 = np.where(~ind)[0]\n",
    "        if idx0.size > 0:\n",
    "            turn_on = np.random.choice(idx0, size=min(kmin-on, idx0.size), replace=False)\n",
    "            ind[turn_on] = True\n",
    "    return ind\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GAConfig:\n",
    "    \"\"\"\n",
    "    Configuraci√≥n para el algoritmo gen√©tico de selecci√≥n de features.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    pop_size : int, default=20\n",
    "        Tama√±o de la poblaci√≥n (n√∫mero de individuos).\n",
    "    p_crossover : float, default=0.8\n",
    "        Probabilidad de realizar crossover entre dos padres.\n",
    "    p_mutation : float, default=0.003\n",
    "        Probabilidad de mutaci√≥n por bit en cada individuo.\n",
    "    generations : int, default=100\n",
    "        N√∫mero de generaciones a ejecutar.\n",
    "    n_points_cx : int, default=2\n",
    "        N√∫mero de puntos de corte para crossover multipunto.\n",
    "    elitism : int, default=0\n",
    "        N√∫mero de mejores individuos a preservar directamente en la siguiente generaci√≥n.\n",
    "    min_features : int, default=3\n",
    "        N√∫mero m√≠nimo de features que debe tener cada individuo.\n",
    "    n_splits_cv : int, default=5\n",
    "        N√∫mero de divisiones para TimeSeriesSplit en la evaluaci√≥n de fitness.\n",
    "    random_state : int, default=42\n",
    "        Semilla para reproducibilidad.\n",
    "    \"\"\"\n",
    "    pop_size: int = 20\n",
    "    p_crossover: float = 0.8\n",
    "    p_mutation: float = 0.003\n",
    "    generations: int = 100\n",
    "    n_points_cx: int = 2\n",
    "    elitism: int = 0\n",
    "    min_features: int = 3\n",
    "    n_splits_cv: int = 5\n",
    "    random_state: Optional[int] = None\n",
    "\n",
    "\n",
    "class GASelector:\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series, cfg: GAConfig):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.cfg = cfg\n",
    "        np.random.seed(cfg.random_state)\n",
    "        self.n_feat = X.shape[1]\n",
    "\n",
    "        self.pop = np.random.rand(cfg.pop_size, self.n_feat) < 0.5\n",
    "        for i in range(cfg.pop_size):\n",
    "            self.pop[i] = _ensure_min_features(self.pop[i], cfg.min_features)\n",
    "\n",
    "        self.history_best = []   # (gen, fitness, mask)\n",
    "        self.history_scores = [] # fitness por generaci√≥n\n",
    "\n",
    "    def _fitness_all(self, pop):\n",
    "        fits = np.zeros(pop.shape[0], dtype=float)\n",
    "        for i, mask in enumerate(pop):\n",
    "            fits[i] = evaluar_subset_TS(self.X, self.y, mask, n_splits=self.cfg.n_splits_cv)\n",
    "        return fits\n",
    "\n",
    "    def _roulette_select(self, fits, k):\n",
    "        f = np.array(fits, dtype=float)\n",
    "        f = f - f.min() + 1e-12\n",
    "        p = f / f.sum() if f.sum() > 0 else np.ones_like(f) / len(f)\n",
    "        idx = np.random.choice(len(f), size=k, replace=True, p=p)\n",
    "        return idx\n",
    "\n",
    "    def run(self):\n",
    "        cfg = self.cfg\n",
    "        pop = self.pop.copy()\n",
    "        for gen in range(cfg.generations):\n",
    "            fits = self._fitness_all(pop)\n",
    "            self.history_scores.append(fits)\n",
    "\n",
    "            ibest = int(np.argmax(fits))\n",
    "            self.history_best.append((gen, float(fits[ibest]), pop[ibest].copy()))\n",
    "\n",
    "            elite_idx = np.argsort(-fits)[:cfg.elitism]\n",
    "            elites = pop[elite_idx].copy()\n",
    "\n",
    "            parent_idx = self._roulette_select(fits, cfg.pop_size)\n",
    "            parents = pop[parent_idx]\n",
    "\n",
    "            next_pop = []\n",
    "            for i in range(0, cfg.pop_size, 2):\n",
    "                p1 = parents[i].copy()\n",
    "                p2 = parents[i+1].copy() if i+1 < cfg.pop_size else parents[0].copy()\n",
    "                if np.random.rand() < cfg.p_crossover:\n",
    "                    c1, c2 = _multipoint_crossover(p1, p2, n_points=cfg.n_points_cx)\n",
    "                else:\n",
    "                    c1, c2 = p1, p2\n",
    "                c1 = _bitflip_mutation(c1, cfg.p_mutation)\n",
    "                c2 = _bitflip_mutation(c2, cfg.p_mutation)\n",
    "                c1 = _ensure_min_features(c1, cfg.min_features)\n",
    "                c2 = _ensure_min_features(c2, cfg.min_features)\n",
    "                next_pop.append(c1); next_pop.append(c2)\n",
    "\n",
    "            pop = np.array(next_pop[:cfg.pop_size], dtype=bool)\n",
    "\n",
    "            if cfg.elitism > 0:\n",
    "                repl_idx = np.random.choice(cfg.pop_size, size=cfg.elitism, replace=False)\n",
    "                pop[repl_idx] = elites\n",
    "\n",
    "        self.pop = pop\n",
    "        return self\n",
    "\n",
    "    def feature_importance_frequency(self):\n",
    "        masks = [m for _, _, m in self.history_best]\n",
    "        freq = np.sum(np.vstack(masks), axis=0).astype(int)\n",
    "        imp = pd.Series(freq, index=self.X.columns, name=\"freq_best_generations\").sort_values(ascending=False)\n",
    "        return imp\n",
    "\n",
    "\n",
    "def run_ga_feature_ranking(features_df: pd.DataFrame, cfg: GAConfig) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Ejecuta algoritmo gen√©tico para selecci√≥n de features y retorna ranking de importancia.\n",
    "    \n",
    "    Ejecuta un GA completo sobre el conjunto de features para encontrar los mejores\n",
    "    subsets. El ranking se basa en la frecuencia con que cada feature aparece en\n",
    "    los mejores individuos de cada generaci√≥n.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos generados por make_tech_indicators.\n",
    "    cfg : GAConfig\n",
    "        Configuraci√≥n del algoritmo gen√©tico.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Series indexada por nombre de feature, ordenada de mayor a menor importancia.\n",
    "        Los valores representan la frecuencia con que cada feature apareci√≥ en los\n",
    "        mejores individuos a lo largo de todas las generaciones.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Construye X e y autom√°ticamente usando build_xy.\n",
    "    - El ranking es acumulativo: cuenta apariciones en todas las generaciones.\n",
    "    - Features m√°s frecuentes en mejores individuos tienen mayor importancia.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> cfg = GAConfig(pop_size=100, generations=50)\n",
    "    >>> ranking = run_ga_feature_ranking(features, cfg)\n",
    "    >>> print(ranking.head(10))  # Top 10 features m√°s importantes\n",
    "    \"\"\"\n",
    "    X_ga, y_ga = build_xy(features_df)\n",
    "    if cfg.random_state is None: \n",
    "        import time\n",
    "        cfg.random_state = int(time.time() * 1000000) % (2**31)\n",
    "    ga = GASelector(X_ga, y_ga, cfg).run()\n",
    "    ranking = ga.feature_importance_frequency()\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c15e5",
   "metadata": {},
   "source": [
    "## Construcci√≥n de modelos predictivos \n",
    "\n",
    "* LSTM\n",
    "* NAIVE\n",
    "* RandomForest\n",
    "* PCA-SVR\n",
    "\n",
    "Las m√©tricas son en escala normalizada del target y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm(input_shape: tuple, units: int = 128, dropout: float = 0.2, lr: float = 1e-3) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Construye un modelo LSTM de 3 capas para predicci√≥n de series temporales.\n",
    "    \n",
    "    Arquitectura:\n",
    "    - 3 capas LSTM apiladas con activaci√≥n ELU\n",
    "    - Dropout despu√©s de cada capa LSTM\n",
    "    - Capa densa final con 1 neurona (regresi√≥n)\n",
    "    - Optimizador Adam con learning rate configurable\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : tuple\n",
    "        Shape de entrada (lookback, n_features). Ejemplo: (5, 10) para 5 per√≠odos y 10 features.\n",
    "    units : int, default=128\n",
    "        N√∫mero de unidades en cada capa LSTM.\n",
    "    dropout : float, default=0.2\n",
    "        Tasa de dropout aplicada despu√©s de cada capa LSTM.\n",
    "    lr : float, default=1e-3\n",
    "        Learning rate para el optimizador Adam.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tf.keras.Model\n",
    "        Modelo LSTM compilado listo para entrenar.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Las primeras dos capas LSTM tienen return_sequences=True.\n",
    "    - La √∫ltima capa LSTM tiene return_sequences=False.\n",
    "    - Loss: MSE, M√©trica: RMSE.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = make_lstm(input_shape=(5, 10), units=64, dropout=0.3)\n",
    "    >>> model.summary()\n",
    "    \"\"\"\n",
    "    m = Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "\n",
    "        # 1st LSTM layer\n",
    "        layers.LSTM(\n",
    "            units,\n",
    "            return_sequences=True,\n",
    "            activation=\"elu\"\n",
    "        ),\n",
    "        layers.Dropout(dropout),\n",
    "\n",
    "        # 2nd LSTM layer\n",
    "        layers.LSTM(\n",
    "            units,\n",
    "            return_sequences=True,\n",
    "            activation=\"elu\"\n",
    "        ),\n",
    "        layers.Dropout(dropout),\n",
    "\n",
    "        # 3rd LSTM layer\n",
    "        layers.LSTM(\n",
    "            units,\n",
    "            return_sequences=False,\n",
    "            activation=\"elu\"\n",
    "        ),\n",
    "        layers.Dropout(dropout),\n",
    "\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    m.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mse\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")],\n",
    "    )\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "def eval_lstm_once(\n",
    "    feature_list: Sequence[str],\n",
    "    splits: SplitDates,\n",
    "    base_features_df: pd.DataFrame,\n",
    "    lookback: int = 5,\n",
    "    seed: int = 123\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Entrena un modelo LSTM una vez y retorna m√©tricas en escala normalizada.\n",
    "    \n",
    "    Prepara los datos, entrena el modelo con early stopping y eval√∫a en\n",
    "    train, validation y test. Todas las m√©tricas est√°n en escala normalizada [0, 1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_list : Sequence[str]\n",
    "        Lista de nombres de features a usar.\n",
    "    splits : SplitDates\n",
    "        Objeto con fechas de corte para train, validation y test.\n",
    "    base_features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos.\n",
    "    lookback : int, default=5\n",
    "        N√∫mero de per√≠odos hacia atr√°s en cada secuencia.\n",
    "    seed : int, default=123\n",
    "        Semilla para reproducibilidad.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con m√©tricas:\n",
    "        - \"train_rmse\", \"val_rmse\", \"test_rmse\": RMSE en escala normalizada\n",
    "        - \"train_mse\", \"val_mse\", \"test_mse\": MSE en escala normalizada\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Usa EarlyStopping con patience=10 y restore_best_weights=True.\n",
    "    - M√°ximo 100 √©pocas, batch_size=512.\n",
    "    - Las m√©tricas est√°n en escala normalizada, no en d√≥lares.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> features = [\"RSI_14\", \"MACD\", \"Price\"]\n",
    "    >>> results = eval_lstm_once(features, splits, features_df, lookback=5)\n",
    "    >>> print(f\"Test RMSE: {results['test_rmse']:.6f}\")\n",
    "    \"\"\"\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    prep = prepare_lstm_data(\n",
    "        features_df=base_features_df,\n",
    "        split_dates=splits,\n",
    "        cfg=LSTMPrepConfig(lookback=lookback, horizon=1, selected_features=feature_list),\n",
    "    )\n",
    "    Xtr, ytr = prep[\"X_train\"], prep[\"y_train\"]\n",
    "    Xva, yva = prep[\"X_val\"],   prep[\"y_val\"]\n",
    "    Xte, yte = prep[\"X_test\"],  prep[\"y_test\"]\n",
    "\n",
    "    model = make_lstm(Xtr.shape[1:])\n",
    "    es = callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True) # TODO hice un cambio aqu√≠\n",
    "\n",
    "    model.fit(\n",
    "        Xtr, ytr,\n",
    "        validation_data=(Xva, yva),\n",
    "        epochs=100,\n",
    "        batch_size=512,\n",
    "        callbacks=[es],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    loss_tr, rmse_tr = model.evaluate(Xtr, ytr, verbose=0)\n",
    "    loss_va, rmse_va = model.evaluate(Xva, yva, verbose=0)\n",
    "    loss_te, rmse_te = model.evaluate(Xte, yte, verbose=0)\n",
    "\n",
    "    return {\n",
    "        \"train_rmse\": float(rmse_tr),\n",
    "        \"val_rmse\":   float(rmse_va),\n",
    "        \"test_rmse\":  float(rmse_te),\n",
    "        \"train_mse\":  float(loss_tr),\n",
    "        \"val_mse\":    float(loss_va),\n",
    "        \"test_mse\":   float(loss_te),\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_lstm_multirun(\n",
    "    feature_list: Sequence[str],\n",
    "    splits: SplitDates,\n",
    "    base_features_df: pd.DataFrame,\n",
    "    runs: int = 3,\n",
    "    lookback: int = 5,\n",
    "    seed0: int = 123\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Entrena un modelo LSTM m√∫ltiples veces y retorna estad√≠sticas agregadas.\n",
    "    \n",
    "    Ejecuta eval_lstm_once varias veces con diferentes semillas y calcula\n",
    "    media y desviaci√≥n est√°ndar de las m√©tricas para obtener resultados m√°s robustos.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_list : Sequence[str]\n",
    "        Lista de nombres de features a usar.\n",
    "    splits : SplitDates\n",
    "        Objeto con fechas de corte.\n",
    "    base_features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos.\n",
    "    runs : int, default=3\n",
    "        N√∫mero de ejecuciones independientes con diferentes semillas.\n",
    "    lookback : int, default=5\n",
    "        N√∫mero de per√≠odos hacia atr√°s en cada secuencia.\n",
    "    seed0 : int, default=123\n",
    "        Semilla base. Se usa seed0, seed0+1, ..., seed0+runs-1 para cada ejecuci√≥n.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con estad√≠sticas agregadas:\n",
    "        - \"train_mean\", \"val_mean\", \"test_mean\": RMSE medio\n",
    "        - \"train_std\", \"val_std\", \"test_std\": Desviaci√≥n est√°ndar de RMSE\n",
    "        - \"train_mse_mean\", \"val_mse_mean\", \"test_mse_mean\": MSE medio\n",
    "        - \"train_mse_std\", \"val_mse_std\", \"test_mse_std\": Desviaci√≥n est√°ndar de MSE\n",
    "        - \"runs\": N√∫mero de ejecuciones realizadas\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> results = eval_lstm_multirun(features, splits, features_df, runs=5)\n",
    "    >>> print(f\"Test RMSE: {results['test_mean']:.6f} ¬± {results['test_std']:.6f}\")\n",
    "    \"\"\"\n",
    "    res = [eval_lstm_once(feature_list, splits, base_features_df, lookback, seed0 + i) for i in range(runs)]\n",
    "    df = pd.DataFrame(res)\n",
    "    return {\n",
    "        \"train_mean\":     df[\"train_rmse\"].mean(),\n",
    "        \"train_std\":      df[\"train_rmse\"].std(ddof=1),\n",
    "        \"val_mean\":       df[\"val_rmse\"].mean(),\n",
    "        \"val_std\":        df[\"val_rmse\"].std(ddof=1),\n",
    "        \"test_mean\":      df[\"test_rmse\"].mean(),\n",
    "        \"test_std\":       df[\"test_rmse\"].std(ddof=1),\n",
    "        \"train_mse_mean\": df[\"train_mse\"].mean(),\n",
    "        \"train_mse_std\":  df[\"train_mse\"].std(ddof=1),\n",
    "        \"val_mse_mean\":   df[\"val_mse\"].mean(),\n",
    "        \"val_mse_std\":    df[\"val_mse\"].std(ddof=1),\n",
    "        \"test_mse_mean\":  df[\"test_mse\"].mean(),\n",
    "        \"test_mse_std\":   df[\"test_mse\"].std(ddof=1),\n",
    "        \"runs\": runs,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_naive_persistence(features_df: pd.DataFrame, splits: SplitDates) -> dict:\n",
    "    \"\"\"\n",
    "    Eval√∫a el modelo Naive (persistencia): predice que el precio siguiente = precio actual.\n",
    "    \n",
    "    Baseline simple que asume que el precio del siguiente per√≠odo es igual al precio actual.\n",
    "    √ötil como referencia para comparar con modelos m√°s complejos.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos (debe contener columna \"Price\").\n",
    "    splits : SplitDates\n",
    "        Objeto con fechas de corte para train, validation y test.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con MSE en escala normalizada:\n",
    "        - \"train_mse\", \"val_mse\", \"test_mse\": MSE en escala [0, 1]\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Usa el mismo escalado MinMax que otros modelos (fit solo en train).\n",
    "    - Predicci√≥n: y_pred[t] = Price[t] (precio actual).\n",
    "    - Target real: y_true[t] = Price[t+1] (precio siguiente).\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> naive_results = eval_naive_persistence(features, splits)\n",
    "    >>> print(f\"Naive Test MSE: {naive_results['test_mse']:.6f}\")\n",
    "    \"\"\"\n",
    "    X, y = build_xy(features_df)\n",
    "\n",
    "    price_t = X[\"Price\"].astype(float).values\n",
    "    y_all   = y.values.astype(np.float32)\n",
    "\n",
    "    idx = X.index\n",
    "    train_mask = idx <= pd.to_datetime(splits.train_end)\n",
    "    val_mask   = (idx > pd.to_datetime(splits.train_end)) & (idx <= pd.to_datetime(splits.val_end))\n",
    "    test_mask  = idx > pd.to_datetime(splits.val_end) if splits.test_end is None else (\n",
    "                 (idx > pd.to_datetime(splits.val_end)) & (idx <= pd.to_datetime(splits.test_end)))\n",
    "\n",
    "    y_train  = y_all[train_mask]\n",
    "    scaler_y = TimeScalerY().fit(y_train) # Ajustar solo con y_train \n",
    "\n",
    "    y_scaled       = scaler_y.transform(y_all)\n",
    "    price_t_scaled = scaler_y.transform(price_t)\n",
    "\n",
    "    def _mse(mask):\n",
    "        return mean_squared_error(y_scaled[mask], price_t_scaled[mask])\n",
    "\n",
    "    return {\n",
    "        \"train_mse\": _mse(train_mask),\n",
    "        \"val_mse\":   _mse(val_mask),\n",
    "        \"test_mse\":  _mse(test_mask),\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_rf_baseline(\n",
    "    feature_list: Sequence[str],\n",
    "    splits: SplitDates,\n",
    "    base_features_df: pd.DataFrame,\n",
    "    lookback: int = 5,\n",
    "    seed: int = 123\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Eval√∫a un modelo Random Forest sobre ventanas temporales aplanadas.\n",
    "    \n",
    "    Usa Random Forest de sklearn sobre secuencias temporales convertidas a formato tabular\n",
    "    (ventanas aplanadas). Cada ventana de lookback per√≠odos se convierte en un vector 1D.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_list : Sequence[str]\n",
    "        Lista de nombres de features a usar.\n",
    "    splits : SplitDates\n",
    "        Objeto con fechas de corte.\n",
    "    base_features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos.\n",
    "    lookback : int, default=5\n",
    "        N√∫mero de per√≠odos hacia atr√°s en cada ventana.\n",
    "    seed : int, default=123\n",
    "        Semilla para reproducibilidad.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con MSE en escala normalizada:\n",
    "        - \"train_mse\", \"val_mse\", \"test_mse\": MSE en escala [0, 1]\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Usa RandomForestRegressor con 300 √°rboles, max_depth=None, n_jobs=-1.\n",
    "    - Las ventanas se aplanan: (n, lookback, n_features) -> (n, lookback * n_features).\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> rf_results = eval_rf_baseline(features, splits, features_df, lookback=5)\n",
    "    >>> print(f\"RF Test MSE: {rf_results['test_mse']:.6f}\")\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    prep = prepare_lstm_data(\n",
    "        features_df=base_features_df,\n",
    "        split_dates=splits,\n",
    "        cfg=LSTMPrepConfig(lookback=lookback, horizon=1, selected_features=feature_list),\n",
    "    )\n",
    "    Xtr, ytr, Xva, yva, Xte, yte = prepare_tabular_from_lstm_prep(prep)\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    rf.fit(Xtr, ytr)\n",
    "\n",
    "    pr_tr = rf.predict(Xtr)\n",
    "    pr_va = rf.predict(Xva)\n",
    "    pr_te = rf.predict(Xte)\n",
    "\n",
    "    return {\n",
    "        \"train_mse\": mean_squared_error(ytr, pr_tr),\n",
    "        \"val_mse\":   mean_squared_error(yva, pr_va),\n",
    "        \"test_mse\":  mean_squared_error(yte, pr_te),\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_pca_svr_baseline(\n",
    "    feature_list: Sequence[str],\n",
    "    splits: SplitDates,\n",
    "    base_features_df: pd.DataFrame,\n",
    "    lookback: int = 5,\n",
    "    seed: int = 123\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Eval√∫a un modelo PCA + SVR sobre ventanas temporales aplanadas.\n",
    "    \n",
    "    Aplica reducci√≥n de dimensionalidad con PCA (95% de varianza) seguido de\n",
    "    Support Vector Regression con kernel RBF sobre ventanas temporales aplanadas.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_list : Sequence[str]\n",
    "        Lista de nombres de features a usar.\n",
    "    splits : SplitDates\n",
    "        Objeto con fechas de corte.\n",
    "    base_features_df : pd.DataFrame\n",
    "        DataFrame con features t√©cnicos.\n",
    "    lookback : int, default=5\n",
    "        N√∫mero de per√≠odos hacia atr√°s en cada ventana.\n",
    "    seed : int, default=123\n",
    "        Semilla para reproducibilidad.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con MSE en escala normalizada:\n",
    "        - \"train_mse\", \"val_mse\", \"test_mse\": MSE en escala [0, 1]\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - PCA retiene componentes que explican 95% de la varianza.\n",
    "    - SVR usa kernel RBF con C=10.0 y epsilon=0.01.\n",
    "    - Las ventanas se aplanan antes de aplicar PCA.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> pca_results = eval_pca_svr_baseline(features, splits, features_df, lookback=5)\n",
    "    >>> print(f\"PCA-SVR Test MSE: {pca_results['test_mse']:.6f}\")\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    prep = prepare_lstm_data(\n",
    "        features_df=base_features_df,\n",
    "        split_dates=splits,\n",
    "        cfg=LSTMPrepConfig(lookback=lookback, horizon=1, selected_features=feature_list),\n",
    "    )\n",
    "    Xtr, ytr, Xva, yva, Xte, yte = prepare_tabular_from_lstm_prep(prep)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"pca\", PCA(n_components=0.95, random_state=seed)),\n",
    "        (\"svr\", SVR(kernel=\"rbf\", C=10.0, epsilon=0.01)),\n",
    "    ])\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    pr_tr = model.predict(Xtr)\n",
    "    pr_va = model.predict(Xva)\n",
    "    pr_te = model.predict(Xte)\n",
    "\n",
    "    return {\n",
    "        \"train_mse\": mean_squared_error(ytr, pr_tr),\n",
    "        \"val_mse\":   mean_squared_error(yva, pr_va),\n",
    "        \"test_mse\":  mean_squared_error(yte, pr_te),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2a2c7",
   "metadata": {},
   "source": [
    "## Resultados Experimentales / Reporter√≠a\n",
    "\n",
    "* Reporte por acci√≥n\n",
    "* Reporte multi-acci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1e79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_asset_report(\n",
    "    csv_path: str,\n",
    "    symbol: str,\n",
    "    start_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "    end_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "    ks: Sequence[int] = (5, 10, 20, 30),\n",
    "    lookbacks: Sequence[int] = (5,10),\n",
    "    runs: int = 3,\n",
    "    ga_cfg: GAConfig = GAConfig(\n",
    "        pop_size=100,\n",
    "        p_crossover=0.8,\n",
    "        p_mutation=0.003,\n",
    "        generations=100,\n",
    "        n_points_cx=4,\n",
    "        elitism=0,\n",
    "        min_features=3,\n",
    "        n_splits_cv=5,\n",
    "        random_state= None,\n",
    "    ),\n",
    "    return_ranking: bool = False,\n",
    "    train_ratio: float = 0.7,\n",
    "    val_ratio: float = 0.1,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline completo de evaluaci√≥n para una acci√≥n individual.\n",
    "    \n",
    "    Realiza todas las etapas del proceso:\n",
    "    1. Carga datos OHLCV desde CSV\n",
    "    2. Genera indicadores t√©cnicos\n",
    "    3. Opcionalmente recorta datos por rango de fechas\n",
    "    4. Ejecuta algoritmo gen√©tico para ranking de features\n",
    "    5. Eval√∫a m√∫ltiples modelos (Naive, RF, PCA-SVR, LSTM, GA-LSTM) para cada lookback\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Ruta al archivo CSV con datos OHLCV. Debe tener columnas: Date, Open, High, Low, Close, Volume.\n",
    "    symbol : str\n",
    "        S√≠mbolo/ticker de la acci√≥n (ej: \"AAPL\", \"MSFT\").\n",
    "    start_date : Optional[Union[str, pd.Timestamp]], default=None\n",
    "        Fecha de inicio para recortar datos. Si None, usa desde el inicio.\n",
    "    end_date : Optional[Union[str, pd.Timestamp]], default=None\n",
    "        Fecha de fin para recortar datos. Si None, usa hasta el final.\n",
    "    ks : Sequence[int], default=(5, 10, 20, 30)\n",
    "        Lista de valores k para GA-LSTM (n√∫mero de top features a usar).\n",
    "    lookbacks : Sequence[int], default=(5, 10)\n",
    "        Lista de valores de lookback (ventanas temporales) a evaluar.\n",
    "    runs : int, default=3\n",
    "        N√∫mero de ejecuciones independientes para modelos LSTM (para promediar).\n",
    "    ga_cfg : GAConfig, default=GAConfig(...)\n",
    "        Configuraci√≥n del algoritmo gen√©tico.\n",
    "    return_ranking : bool, default=False\n",
    "        Si True, retorna tambi√©n el ranking de features del GA.\n",
    "    train_ratio : float, default=0.7\n",
    "        Proporci√≥n de datos para entrenamiento.\n",
    "    val_ratio : float, default=0.1\n",
    "        Proporci√≥n de datos para validaci√≥n.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or tuple\n",
    "        Si return_ranking=False: DataFrame con resultados.\n",
    "        Si return_ranking=True: Tupla (DataFrame, pd.Series) con resultados y ranking.\n",
    "        \n",
    "        El DataFrame tiene columnas:\n",
    "        - symbol: S√≠mbolo de la acci√≥n\n",
    "        - lookback: Valor de lookback usado\n",
    "        - modelo: Nombre del modelo (\"Naive\", \"RF (todas)\", \"PCA-SVR (todas)\", \"LSTM (todas)\", \"GA-LSTM (k=X)\")\n",
    "        - k: N√∫mero de features (o \"-\" si no aplica)\n",
    "        - train_mse, val_mse, test_mse: MSE en escala normalizada\n",
    "        - train_rmse_real, val_rmse_real, test_rmse_real: RMSE en d√≥lares reales\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Los errores en d√≥lares se calculan usando el rango de precios en train.\n",
    "    - El modelo Naive se eval√∫a una vez (no depende de lookback).\n",
    "    - Los modelos LSTM se ejecutan m√∫ltiples veces y se promedian.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> report = run_asset_report(\n",
    "    ...     csv_path=\"data/aapl.csv\",\n",
    "    ...     symbol=\"AAPL\",\n",
    "    ...     start_date=\"2020-01-01\",\n",
    "    ...     end_date=\"2021-12-31\",\n",
    "    ...     ks=(5, 10, 20),\n",
    "    ...     lookbacks=(5,)\n",
    "    ... )\n",
    "    >>> print(report.head())\n",
    "    \"\"\"\n",
    "    # 1) Cargar datos OHLCV y features\n",
    "    df_ohlcv = pd.read_csv(csv_path).set_index(\"Date\").sort_index()\n",
    "    features = make_tech_indicators(\n",
    "        df_ohlcv,\n",
    "        safe=False,\n",
    "        price_col=\"Close\",\n",
    "        high_col=\"High\",\n",
    "        low_col=\"Low\",\n",
    "        vol_col=\"Volume\",\n",
    "    )\n",
    "\n",
    "    # Recorte opcional de ventana de tiempo [start_date, end_date]\n",
    "    # -----------------------------------------------------------\n",
    "    \n",
    "    if (start_date is not None) or (end_date is not None):\n",
    "        features[\"Date\"] = pd.to_datetime(features[\"Date\"])\n",
    "        features = features.set_index(\"Date\").sort_index()\n",
    "        \n",
    "        start = pd.to_datetime(start_date) if start_date is not None else features.index.min()\n",
    "        end   = pd.to_datetime(end_date)   if end_date   is not None else features.index.max()\n",
    "        features = features.loc[start:end].reset_index()\n",
    "        \n",
    "    # Rango de precios en train para pasar de MSE[0,1] a error real en d√≥lares\n",
    "    # (sobre ventana recortada, si es que se us√≥)\n",
    "    # -----------------------------------------------------------\n",
    "    X_y, y = build_xy(features)\n",
    "    splits = SplitDates.from_ratios(X_y=X_y, train_ratio=train_ratio, val_ratio=val_ratio)\n",
    "    \n",
    "    (_, y_tr), _, _ = time_splits(X_y, y, splits)\n",
    "    y_range = float(y_tr.max() - y_tr.min())\n",
    "\n",
    "   # 2) GA -> ranking de features\n",
    "    ranking = run_ga_feature_ranking(features, ga_cfg)\n",
    "    feats_ordenados = list(ranking.index)\n",
    "    all_features = list(X_y.columns)\n",
    "\n",
    "    filas = []\n",
    "\n",
    "    # Naive (no depende de lookback)\n",
    "    naive_res = eval_naive_persistence(features, splits)\n",
    "\n",
    "    for lookback in lookbacks:\n",
    "        # Baselines con todas las features\n",
    "        rf_all_res = eval_rf_baseline(all_features, splits, features, lookback=lookback)\n",
    "        pca_all_res = eval_pca_svr_baseline(all_features, splits, features, lookback=lookback)\n",
    "        lstm_all_res = eval_lstm_multirun(\n",
    "            feature_list=all_features,\n",
    "            splits=splits,\n",
    "            base_features_df=features,\n",
    "            runs=runs,\n",
    "            lookback=lookback,\n",
    "            seed0=200,\n",
    "        )\n",
    "\n",
    "        # Naive\n",
    "        filas.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"lookback\": lookback,\n",
    "            \"modelo\": \"Naive\",\n",
    "            \"k\": \"-\",\n",
    "            \"train_mse\": naive_res[\"train_mse\"],\n",
    "            \"val_mse\": naive_res[\"val_mse\"],\n",
    "            \"test_mse\": naive_res[\"test_mse\"],\n",
    "            \"train_rmse_real\": (naive_res[\"train_mse\"] ** 0.5) * y_range,\n",
    "            \"val_rmse_real\":  (naive_res[\"val_mse\"]  ** 0.5) * y_range,\n",
    "            \"test_rmse_real\": (naive_res[\"test_mse\"] ** 0.5) * y_range,\n",
    "        })\n",
    "\n",
    "        # RF / PCA-SVR / LSTM (todas)\n",
    "        filas.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"lookback\": lookback,\n",
    "            \"modelo\": \"RF (todas)\",\n",
    "            \"k\": \"-\",\n",
    "            \"train_mse\": rf_all_res[\"train_mse\"],\n",
    "            \"val_mse\": rf_all_res[\"val_mse\"],\n",
    "            \"test_mse\": rf_all_res[\"test_mse\"],\n",
    "            \"train_rmse_real\": (rf_all_res[\"train_mse\"] ** 0.5) * y_range,\n",
    "            \"val_rmse_real\":  (rf_all_res[\"val_mse\"]  ** 0.5) * y_range,\n",
    "            \"test_rmse_real\": (rf_all_res[\"test_mse\"] ** 0.5) * y_range,\n",
    "        })\n",
    "        filas.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"lookback\": lookback,\n",
    "            \"modelo\": \"PCA-SVR (todas)\",\n",
    "            \"k\": \"-\",\n",
    "            \"train_mse\": pca_all_res[\"train_mse\"],\n",
    "            \"val_mse\": pca_all_res[\"val_mse\"],\n",
    "            \"test_mse\": pca_all_res[\"test_mse\"],\n",
    "            \"train_rmse_real\": (pca_all_res[\"train_mse\"] ** 0.5) * y_range,\n",
    "            \"val_rmse_real\":  (pca_all_res[\"val_mse\"]  ** 0.5) * y_range,\n",
    "            \"test_rmse_real\": (pca_all_res[\"test_mse\"] ** 0.5) * y_range,\n",
    "        })\n",
    "        filas.append({\n",
    "            \"symbol\": symbol,\n",
    "            \"lookback\": lookback,\n",
    "            \"modelo\": \"LSTM (todas)\",\n",
    "            \"k\": \"-\",\n",
    "            \"train_mse\": lstm_all_res[\"train_mse_mean\"],\n",
    "            \"val_mse\": lstm_all_res[\"val_mse_mean\"],\n",
    "            \"test_mse\": lstm_all_res[\"test_mse_mean\"],\n",
    "            \"train_rmse_real\": lstm_all_res[\"train_mean\"] * y_range,\n",
    "            \"val_rmse_real\":  lstm_all_res[\"val_mean\"]  * y_range,\n",
    "            \"test_rmse_real\": lstm_all_res[\"test_mean\"] * y_range,\n",
    "        })\n",
    "\n",
    "        # GA-LSTM para distintos k\n",
    "        for k in ks:\n",
    "            selected = feats_ordenados[:k]\n",
    "            lstm_ga_res = eval_lstm_multirun(\n",
    "                feature_list=selected,\n",
    "                splits=splits,\n",
    "                base_features_df=features,\n",
    "                runs=runs,\n",
    "                lookback=lookback,\n",
    "                seed0=123,\n",
    "            )\n",
    "            filas.append({\n",
    "                \"symbol\": symbol,\n",
    "                \"lookback\": lookback,\n",
    "                \"modelo\": f\"GA-LSTM (k={k})\",\n",
    "                \"k\": k,\n",
    "                \"train_mse\": lstm_ga_res[\"train_mse_mean\"],\n",
    "                \"val_mse\": lstm_ga_res[\"val_mse_mean\"],\n",
    "                \"test_mse\": lstm_ga_res[\"test_mse_mean\"],\n",
    "                \"train_rmse_real\": lstm_ga_res[\"train_mean\"] * y_range,\n",
    "                \"val_rmse_real\":  lstm_ga_res[\"val_mean\"]  * y_range,\n",
    "                \"test_rmse_real\": lstm_ga_res[\"test_mean\"] * y_range,\n",
    "            })\n",
    "\n",
    "    reporte = pd.DataFrame(filas)\n",
    "    \n",
    "    if return_ranking: \n",
    "        return reporte, ranking\n",
    "    \n",
    "    return reporte\n",
    "\n",
    "\n",
    "\n",
    "def run_multi_asset_report(\n",
    "    symbol_to_path: Mapping[str, str],\n",
    "    start_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "    end_date: Optional[Union[str, pd.Timestamp]] = None,\n",
    "    ks: Sequence[int] = (5, 10, 20, 30),\n",
    "    lookbacks: Sequence[int] = (5,),\n",
    "    runs: int = 3,\n",
    "    ga_cfg: GAConfig = GAConfig(\n",
    "        pop_size=100,\n",
    "        p_crossover=0.8,\n",
    "        p_mutation=0.003,\n",
    "        generations=100,\n",
    "        n_points_cx=4,\n",
    "        elitism=0,\n",
    "        min_features=3,\n",
    "        n_splits_cv=5,\n",
    "        random_state=123,\n",
    "    ),\n",
    "    train_ratio: float = 0.7,\n",
    "    val_ratio: float = 0.1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline completo para m√∫ltiples acciones y concatena los resultados.\n",
    "    \n",
    "    Itera sobre un diccionario de s√≠mbolos y rutas, ejecutando run_asset_report\n",
    "    para cada uno y concatenando todos los resultados en un solo DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    symbol_to_path : Mapping[str, str]\n",
    "        Diccionario que mapea s√≠mbolos (tickers) a rutas de archivos CSV.\n",
    "        Ejemplo: {\"AAPL\": \"data/aapl.csv\", \"MSFT\": \"data/msft.csv\"}\n",
    "    start_date : Optional[Union[str, pd.Timestamp]], default=None\n",
    "        Fecha de inicio para recortar datos (aplicada a todas las acciones).\n",
    "    end_date : Optional[Union[str, pd.Timestamp]], default=None\n",
    "        Fecha de fin para recortar datos (aplicada a todas las acciones).\n",
    "    ks : Sequence[int], default=(5, 10, 20, 30)\n",
    "        Lista de valores k para GA-LSTM.\n",
    "    lookbacks : Sequence[int], default=(5,)\n",
    "        Lista de valores de lookback a evaluar.\n",
    "    runs : int, default=3\n",
    "        N√∫mero de ejecuciones para modelos LSTM.\n",
    "    ga_cfg : GAConfig, default=GAConfig(...)\n",
    "        Configuraci√≥n del algoritmo gen√©tico.\n",
    "    train_ratio : float, default=0.7\n",
    "        Proporci√≥n de datos para entrenamiento.\n",
    "    val_ratio : float, default=0.1\n",
    "        Proporci√≥n de datos para validaci√≥n.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con todos los resultados concatenados. Tiene las mismas columnas\n",
    "        que run_asset_report, pero con m√∫ltiples s√≠mbolos.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - Cada acci√≥n se procesa independientemente.\n",
    "    - El GA se ejecuta por separado para cada acci√≥n.\n",
    "    - Los resultados se concatenan manteniendo todas las columnas.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> symbol_to_path = {\n",
    "    ...     \"AAPL\": \"data/aapl.csv\",\n",
    "    ...     \"MSFT\": \"data/msft.csv\",\n",
    "    ...     \"SP500\": \"data/spy.csv\"\n",
    "    ... }\n",
    "    >>> df_all = run_multi_asset_report(\n",
    "    ...     symbol_to_path=symbol_to_path,\n",
    "    ...     start_date=\"2020-01-01\",\n",
    "    ...     end_date=\"2021-12-31\"\n",
    "    ... )\n",
    "    >>> print(df_all.groupby(\"symbol\")[\"test_rmse_real\"].mean())\n",
    "    \"\"\"\n",
    "    reports = []\n",
    "    for symbol, path in symbol_to_path.items():\n",
    "        rep = run_asset_report(\n",
    "            csv_path=path,\n",
    "            symbol=symbol,\n",
    "            ks=ks,\n",
    "            lookbacks=lookbacks,\n",
    "            runs=runs,\n",
    "            ga_cfg=ga_cfg,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            train_ratio=train_ratio,\n",
    "            val_ratio=val_ratio,\n",
    "        )\n",
    "        reports.append(rep)\n",
    "\n",
    "    return pd.concat(reports, ignore_index=True)\n",
    "\n",
    "def build_symbol_reports(df: pd.DataFrame) -> dict[str, pd.DataFrame]:\n",
    "    reports = {}\n",
    "    for sym, g in df.groupby(\"symbol\"):\n",
    "        # Ordenado bonito y con √≠ndice compuesto\n",
    "        g2 = (\n",
    "            g.sort_values([\"lookback\", \"modelo\"])\n",
    "             .set_index([\"lookback\", \"modelo\"])\n",
    "        )\n",
    "        reports[sym] = g2\n",
    "    return reports\n",
    "\n",
    "\n",
    "def display_results_table(df: pd.DataFrame, symbol: Optional[str] = None, \n",
    "                          sort_by: str = \"test_rmse_real\", ascending: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Muestra un DataFrame bien formateado con todos los resultados.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame con resultados (de run_asset_report o run_multi_asset_report)\n",
    "    symbol : str, optional\n",
    "        Si se especifica, filtra por ese s√≠mbolo\n",
    "    sort_by : str\n",
    "        Columna por la cual ordenar (default: \"test_rmse_real\")\n",
    "    ascending : bool\n",
    "        Orden ascendente o descendente\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame formateado con todas las m√©tricas\n",
    "    \"\"\"\n",
    "    display_df = df.copy()\n",
    "    \n",
    "    if symbol is not None:\n",
    "        display_df = display_df[display_df[\"symbol\"] == symbol].copy()\n",
    "    \n",
    "    # Ordenar columnas de forma l√≥gica\n",
    "    col_order = [\"symbol\", \"lookback\", \"modelo\", \"k\", \n",
    "                 \"train_mse\", \"val_mse\", \"test_mse\",\n",
    "                 \"train_rmse_real\", \"val_rmse_real\", \"test_rmse_real\"]\n",
    "    \n",
    "    # Asegurar que todas las columnas existan\n",
    "    available_cols = [c for c in col_order if c in display_df.columns]\n",
    "    other_cols = [c for c in display_df.columns if c not in col_order]\n",
    "    display_df = display_df[available_cols + other_cols]\n",
    "    \n",
    "    # Guardar tipos num√©ricos antes de formatear\n",
    "    numeric_cols = display_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Ordenar por la columna especificada (antes de formatear)\n",
    "    if sort_by in display_df.columns:\n",
    "        display_df = display_df.sort_values(sort_by, ascending=ascending)\n",
    "    \n",
    "    # Formatear valores num√©ricos para mejor legibilidad (despu√©s de ordenar)\n",
    "    for col in numeric_cols:\n",
    "        if \"mse\" in col.lower():\n",
    "            display_df[col] = display_df[col].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else \"N/A\")\n",
    "        elif \"rmse_real\" in col.lower():\n",
    "            display_df[col] = display_df[col].apply(lambda x: f\"{x:.4f}\" if pd.notna(x) else \"N/A\")\n",
    "        else:\n",
    "            display_df[col] = display_df[col].apply(lambda x: f\"{x:.4f}\" if pd.notna(x) else \"N/A\")\n",
    "    \n",
    "    return display_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def display_results_summary(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Muestra un resumen de resultados agrupado por s√≠mbolo y modelo.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(\"RESUMEN DE RESULTADOS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for symbol in df[\"symbol\"].unique():\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"SYMBOL: {symbol}\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        symbol_df = df[df[\"symbol\"] == symbol].copy()\n",
    "        \n",
    "        # Mejor modelo por test_rmse_real\n",
    "        best_test = symbol_df.loc[symbol_df[\"test_rmse_real\"].idxmin()]\n",
    "        print(f\"\\nüèÜ Mejor modelo (menor test RMSE): {best_test['modelo']} (lookback={best_test['lookback']}, k={best_test['k']})\")\n",
    "        print(f\"   Test RMSE: {best_test['test_rmse_real']:.4f} USD | Test MSE: {best_test['test_mse']:.6f}\")\n",
    "        \n",
    "        # Tabla resumida por modelo\n",
    "        summary = symbol_df.groupby(\"modelo\").agg({\n",
    "            \"test_rmse_real\": [\"mean\", \"min\", \"std\"],\n",
    "            \"val_rmse_real\": [\"mean\", \"min\", \"std\"],\n",
    "            \"test_mse\": [\"mean\", \"min\"]\n",
    "        }).round(4)\n",
    "        \n",
    "        print(f\"\\nüìä Resumen por modelo:\")\n",
    "        print(summary)\n",
    "        \n",
    "        # Tabla completa (convertir a num√©rico temporalmente para ordenar)\n",
    "        print(f\"\\nüìã Tabla completa de resultados:\")\n",
    "        symbol_df_num = symbol_df.copy()\n",
    "        for col in [\"train_mse\", \"val_mse\", \"test_mse\", \"train_rmse_real\", \"val_rmse_real\", \"test_rmse_real\"]:\n",
    "            if col in symbol_df_num.columns:\n",
    "                symbol_df_num[col] = pd.to_numeric(symbol_df_num[col], errors=\"coerce\")\n",
    "        display_table = display_results_table(symbol_df_num, sort_by=\"test_rmse_real\", ascending=True)\n",
    "        print(display_table.to_string(index=False))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4f423",
   "metadata": {},
   "source": [
    "## Funciones de Visualizaci√≥n\n",
    "\n",
    "Se han agregado dos funciones √∫tiles para visualizar los resultados:\n",
    "\n",
    "- `display_results_table()`: Muestra un DataFrame bien formateado con todos los resultados\n",
    "- `display_results_summary()`: Muestra un resumen completo con estad√≠sticas por modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad849223",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d09fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 21:42:30.238380: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Una sola acci√≥n\n",
    "report_aapl, ranking_aapl = run_asset_report(\n",
    "    csv_path=\"Dataset/Stocks/aapl.us.txt\",\n",
    "    symbol=\"AAPL\",\n",
    "    ks=(5, 10, 20, 30),\n",
    "    lookbacks=[5],   # por ejemplo probar lookback 5 zy 10\n",
    "    runs=3,\n",
    "    return_ranking = True,\n",
    "    start_date=\"2009-01-01\",\n",
    "    end_date=\"2011-12-31\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef43e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "RESULTADOS PARA AAPL\n",
      "====================================================================================================\n",
      "symbol lookback          modelo  k train_mse  val_mse test_mse train_rmse_real val_rmse_real test_rmse_real\n",
      "  AAPL   5.0000           Naive  -  0.000148 0.000267 0.000603        0.443497      0.596628       0.895895\n",
      "  AAPL   5.0000    LSTM (todas)  -  0.001037 0.000824 0.002832        1.166560      1.047219       1.931563\n",
      "  AAPL   5.0000  GA-LSTM (k=30) 30  0.002444 0.001100 0.003920        1.680259      1.185609       2.280448\n",
      "  AAPL   5.0000   GA-LSTM (k=5)  5  0.037904 0.002660 0.006836        7.057942      1.865719       2.992523\n",
      "  AAPL   5.0000  GA-LSTM (k=20) 20  0.027500 0.008837 0.016741        4.333710      2.830814       4.007946\n",
      "  AAPL   5.0000      RF (todas)  -  0.000022 0.001451 0.012109        0.169421      1.389969       4.015246\n",
      "  AAPL   5.0000  GA-LSTM (k=10) 10  0.075512 0.033283 0.055815       10.017656      6.609925       8.582962\n",
      "  AAPL   5.0000 PCA-SVR (todas)  -  0.000062 0.012763 0.130160        0.286348      4.122254      13.164048\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "RESUMEN DE RESULTADOS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "SYMBOL: AAPL\n",
      "====================================================================================================\n",
      "\n",
      "üèÜ Mejor modelo (menor test RMSE): Naive (lookback=5, k=-)\n",
      "   Test RMSE: 0.8959 USD | Test MSE: 0.000603\n",
      "\n",
      "üìä Resumen por modelo:\n",
      "                test_rmse_real              val_rmse_real              \\\n",
      "                          mean      min std          mean     min std   \n",
      "modelo                                                                  \n",
      "GA-LSTM (k=10)          8.5830   8.5830 NaN        6.6099  6.6099 NaN   \n",
      "GA-LSTM (k=20)          4.0079   4.0079 NaN        2.8308  2.8308 NaN   \n",
      "GA-LSTM (k=30)          2.2804   2.2804 NaN        1.1856  1.1856 NaN   \n",
      "GA-LSTM (k=5)           2.9925   2.9925 NaN        1.8657  1.8657 NaN   \n",
      "LSTM (todas)            1.9316   1.9316 NaN        1.0472  1.0472 NaN   \n",
      "Naive                   0.8959   0.8959 NaN        0.5966  0.5966 NaN   \n",
      "PCA-SVR (todas)        13.1640  13.1640 NaN        4.1223  4.1223 NaN   \n",
      "RF (todas)              4.0152   4.0152 NaN        1.3900  1.3900 NaN   \n",
      "\n",
      "                test_mse          \n",
      "                    mean     min  \n",
      "modelo                            \n",
      "GA-LSTM (k=10)    0.0558  0.0558  \n",
      "GA-LSTM (k=20)    0.0167  0.0167  \n",
      "GA-LSTM (k=30)    0.0039  0.0039  \n",
      "GA-LSTM (k=5)     0.0068  0.0068  \n",
      "LSTM (todas)      0.0028  0.0028  \n",
      "Naive             0.0006  0.0006  \n",
      "PCA-SVR (todas)   0.1302  0.1302  \n",
      "RF (todas)        0.0121  0.0121  \n",
      "\n",
      "üìã Tabla completa de resultados:\n",
      "symbol lookback          modelo  k train_mse  val_mse test_mse train_rmse_real val_rmse_real test_rmse_real\n",
      "  AAPL   5.0000           Naive  -  0.000148 0.000267 0.000603        0.443497      0.596628       0.895895\n",
      "  AAPL   5.0000    LSTM (todas)  -  0.001037 0.000824 0.002832        1.166560      1.047219       1.931563\n",
      "  AAPL   5.0000  GA-LSTM (k=30) 30  0.002444 0.001100 0.003920        1.680259      1.185609       2.280448\n",
      "  AAPL   5.0000   GA-LSTM (k=5)  5  0.037904 0.002660 0.006836        7.057942      1.865719       2.992523\n",
      "  AAPL   5.0000  GA-LSTM (k=20) 20  0.027500 0.008837 0.016741        4.333710      2.830814       4.007946\n",
      "  AAPL   5.0000      RF (todas)  -  0.000022 0.001451 0.012109        0.169421      1.389969       4.015246\n",
      "  AAPL   5.0000  GA-LSTM (k=10) 10  0.075512 0.033283 0.055815       10.017656      6.609925       8.582962\n",
      "  AAPL   5.0000 PCA-SVR (todas)  -  0.000062 0.012763 0.130160        0.286348      4.122254      13.164048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mostrar resultados en tabla bien formateada\n",
    "print(\"=\" * 100)\n",
    "print(\"RESULTADOS PARA AAPL\")\n",
    "print(\"=\" * 100)\n",
    "display_table = display_results_table(report_aapl, symbol=\"AAPL\", sort_by=\"test_rmse_real\", ascending=True)\n",
    "print(display_table.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "\n",
    "# Tambi√©n mostrar resumen\n",
    "display_results_summary(report_aapl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff95ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "top_n = 20 # ajusta a gusto\n",
    "plot_df = ranking_aapl.sort_values(ascending=False).head(top_n).reset_index()\n",
    "plot_df.columns = [\"feature\", \"importance\"]\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, max(4, int(top_n*0.35))))\n",
    "ax = sns.barplot(data=plot_df, x=\"importance\", y=\"feature\")\n",
    "ax.set(\n",
    "    title=\"Importancia de features (GA)\",\n",
    "    xlabel=\"Importancia (frecuencia en mejores generaciones)\",\n",
    "    ylabel=\"Feature\"\n",
    ")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b185606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "RESUMEN DE RESULTADOS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "SYMBOL: AAPL\n",
      "====================================================================================================\n",
      "\n",
      "üèÜ Mejor modelo (menor test RMSE): Naive (lookback=5, k=-)\n",
      "   Test RMSE: 0.4759 USD | Test MSE: 0.000710\n",
      "\n",
      "üìä Resumen por modelo:\n",
      "                test_rmse_real              val_rmse_real               \\\n",
      "                          mean      min std          mean      min std   \n",
      "modelo                                                                   \n",
      "GA-LSTM (k=10)          0.9789   0.9789 NaN        0.8677   0.8677 NaN   \n",
      "GA-LSTM (k=20)          1.1896   1.1896 NaN        0.9854   0.9854 NaN   \n",
      "GA-LSTM (k=30)          1.3036   1.3036 NaN        1.0380   1.0380 NaN   \n",
      "GA-LSTM (k=5)           1.0473   1.0473 NaN        0.9079   0.9079 NaN   \n",
      "LSTM (todas)            1.4517   1.4517 NaN        1.0001   1.0001 NaN   \n",
      "Naive                   0.4759   0.4759 NaN        0.5669   0.5669 NaN   \n",
      "PCA-SVR (todas)        17.9582  17.9582 NaN       10.1303  10.1303 NaN   \n",
      "RF (todas)             11.3849  11.3849 NaN        4.3816   4.3816 NaN   \n",
      "\n",
      "                test_mse          \n",
      "                    mean     min  \n",
      "modelo                            \n",
      "GA-LSTM (k=10)    0.0030  0.0030  \n",
      "GA-LSTM (k=20)    0.0044  0.0044  \n",
      "GA-LSTM (k=30)    0.0057  0.0057  \n",
      "GA-LSTM (k=5)     0.0035  0.0035  \n",
      "LSTM (todas)      0.0073  0.0073  \n",
      "Naive             0.0007  0.0007  \n",
      "PCA-SVR (todas)   1.0115  1.0115  \n",
      "RF (todas)        0.4065  0.4065  \n",
      "\n",
      "üìã Tabla completa de resultados:\n",
      "symbol lookback          modelo  k train_mse  val_mse test_mse train_rmse_real val_rmse_real test_rmse_real\n",
      "  AAPL   5.0000           Naive  -  0.000071 0.001008 0.000710        0.150806      0.566949       0.475911\n",
      "  AAPL   5.0000  GA-LSTM (k=10) 10  0.000221 0.002362 0.003030        0.265168      0.867728       0.978862\n",
      "  AAPL   5.0000   GA-LSTM (k=5)  5  0.000208 0.002586 0.003450        0.257631      0.907879       1.047288\n",
      "  AAPL   5.0000  GA-LSTM (k=20) 20  0.001071 0.003058 0.004439        0.498372      0.985445       1.189553\n",
      "  AAPL   5.0000  GA-LSTM (k=30) 30  0.001061 0.003398 0.005724        0.481504      1.038004       1.303643\n",
      "  AAPL   5.0000    LSTM (todas)  -  0.000731 0.003139 0.007308        0.429896      1.000055       1.451665\n",
      "  AAPL   5.0000      RF (todas)  -  0.000011 0.060215 0.406534        0.058616      4.381618      11.384931\n",
      "  AAPL   5.0000 PCA-SVR (todas)  -  0.000045 0.321869 1.011495        0.120064     10.130283      17.958237\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "SYMBOL: GE\n",
      "====================================================================================================\n",
      "\n",
      "üèÜ Mejor modelo (menor test RMSE): Naive (lookback=5, k=-)\n",
      "   Test RMSE: 0.4034 USD | Test MSE: 0.000177\n",
      "\n",
      "üìä Resumen por modelo:\n",
      "                test_rmse_real              val_rmse_real              \\\n",
      "                          mean      min std          mean     min std   \n",
      "modelo                                                                  \n",
      "GA-LSTM (k=10)          1.4978   1.4978 NaN        0.7440  0.7440 NaN   \n",
      "GA-LSTM (k=20)          1.6861   1.6861 NaN        0.7188  0.7188 NaN   \n",
      "GA-LSTM (k=30)          1.7421   1.7421 NaN        0.7176  0.7176 NaN   \n",
      "GA-LSTM (k=5)           1.3751   1.3751 NaN        0.7675  0.7675 NaN   \n",
      "LSTM (todas)            2.0212   2.0212 NaN        0.7146  0.7146 NaN   \n",
      "Naive                   0.4034   0.4034 NaN        0.5251  0.5251 NaN   \n",
      "PCA-SVR (todas)        16.3675  16.3675 NaN        2.4068  2.4068 NaN   \n",
      "RF (todas)              7.0459   7.0459 NaN        0.6048  0.6048 NaN   \n",
      "\n",
      "                test_mse          \n",
      "                    mean     min  \n",
      "modelo                            \n",
      "GA-LSTM (k=10)    0.0024  0.0024  \n",
      "GA-LSTM (k=20)    0.0031  0.0031  \n",
      "GA-LSTM (k=30)    0.0033  0.0033  \n",
      "GA-LSTM (k=5)     0.0021  0.0021  \n",
      "LSTM (todas)      0.0045  0.0045  \n",
      "Naive             0.0002  0.0002  \n",
      "PCA-SVR (todas)   0.2909  0.2909  \n",
      "RF (todas)        0.0539  0.0539  \n",
      "\n",
      "üìã Tabla completa de resultados:\n",
      "symbol lookback          modelo  k train_mse  val_mse test_mse train_rmse_real val_rmse_real test_rmse_real\n",
      "    GE   5.0000           Naive  -  0.000353 0.000299 0.000177        0.570464      0.525102       0.403366\n",
      "    GE   5.0000   GA-LSTM (k=5)  5  0.000876 0.000640 0.002062        0.898139      0.767463       1.375112\n",
      "    GE   5.0000  GA-LSTM (k=10) 10  0.000792 0.000601 0.002437        0.853624      0.744036       1.497792\n",
      "    GE   5.0000  GA-LSTM (k=20) 20  0.000740 0.000561 0.003093        0.825019      0.718790       1.686074\n",
      "    GE   5.0000  GA-LSTM (k=30) 30  0.000712 0.000559 0.003299        0.809693      0.717586       1.742053\n",
      "    GE   5.0000    LSTM (todas)  -  0.000645 0.000555 0.004540        0.770075      0.714630       2.021169\n",
      "    GE   5.0000      RF (todas)  -  0.000053 0.000397 0.053917        0.220168      0.604766       7.045912\n",
      "    GE   5.0000 PCA-SVR (todas)  -  0.000080 0.006291 0.290949        0.270840      2.406815      16.367457\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "SYMBOL: BA\n",
      "====================================================================================================\n",
      "\n",
      "üèÜ Mejor modelo (menor test RMSE): Naive (lookback=5, k=-)\n",
      "   Test RMSE: 1.1412 USD | Test MSE: 0.000271\n",
      "\n",
      "üìä Resumen por modelo:\n",
      "                test_rmse_real             val_rmse_real             test_mse  \\\n",
      "                          mean     min std          mean     min std     mean   \n",
      "modelo                                                                          \n",
      "GA-LSTM (k=10)          1.9525  1.9525 NaN        2.1896  2.1896 NaN   0.0008   \n",
      "GA-LSTM (k=20)          2.0497  2.0497 NaN        2.3261  2.3261 NaN   0.0009   \n",
      "GA-LSTM (k=30)          2.1291  2.1291 NaN        2.2429  2.2429 NaN   0.0009   \n",
      "GA-LSTM (k=5)           1.9318  1.9318 NaN        2.1283  2.1283 NaN   0.0008   \n",
      "LSTM (todas)            2.7569  2.7569 NaN        2.3015  2.3015 NaN   0.0016   \n",
      "Naive                   1.1412  1.1412 NaN        1.2456  1.2456 NaN   0.0003   \n",
      "PCA-SVR (todas)         3.3466  3.3466 NaN        3.8059  3.8059 NaN   0.0023   \n",
      "RF (todas)              1.2109  1.2109 NaN        2.0179  2.0179 NaN   0.0003   \n",
      "\n",
      "                         \n",
      "                    min  \n",
      "modelo                   \n",
      "GA-LSTM (k=10)   0.0008  \n",
      "GA-LSTM (k=20)   0.0009  \n",
      "GA-LSTM (k=30)   0.0009  \n",
      "GA-LSTM (k=5)    0.0008  \n",
      "LSTM (todas)     0.0016  \n",
      "Naive            0.0003  \n",
      "PCA-SVR (todas)  0.0023  \n",
      "RF (todas)       0.0003  \n",
      "\n",
      "üìã Tabla completa de resultados:\n",
      "symbol lookback          modelo  k train_mse  val_mse test_mse train_rmse_real val_rmse_real test_rmse_real\n",
      "    BA   5.0000           Naive  -  0.000154 0.000323 0.000271        0.860970      1.245594       1.141241\n",
      "    BA   5.0000      RF (todas)  -  0.000022 0.000849 0.000306        0.323936      2.017850       1.210930\n",
      "    BA   5.0000   GA-LSTM (k=5)  5  0.000415 0.000944 0.000778        1.410605      2.128252       1.931834\n",
      "    BA   5.0000  GA-LSTM (k=10) 10  0.000435 0.001000 0.000795        1.444220      2.189606       1.952452\n",
      "    BA   5.0000  GA-LSTM (k=20) 20  0.000476 0.001130 0.000877        1.509556      2.326099       2.049692\n",
      "    BA   5.0000  GA-LSTM (k=30) 30  0.000465 0.001050 0.000945        1.494106      2.242881       2.129089\n",
      "    BA   5.0000    LSTM (todas)  -  0.000568 0.001105 0.001589        1.634063      2.301506       2.756906\n",
      "    BA   5.0000 PCA-SVR (todas)  -  0.000065 0.003019 0.002334        0.556750      3.805929       3.346557\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "TABLA COMPLETA DE TODOS LOS RESULTADOS\n",
      "====================================================================================================\n",
      "symbol lookback          modelo  k train_mse  val_mse test_mse train_rmse_real val_rmse_real test_rmse_real\n",
      "    GE   5.0000           Naive  -  0.000353 0.000299 0.000177        0.570464      0.525102       0.403366\n",
      "  AAPL   5.0000           Naive  -  0.000071 0.001008 0.000710        0.150806      0.566949       0.475911\n",
      "  AAPL   5.0000  GA-LSTM (k=10) 10  0.000221 0.002362 0.003030        0.265168      0.867728       0.978862\n",
      "  AAPL   5.0000   GA-LSTM (k=5)  5  0.000208 0.002586 0.003450        0.257631      0.907879       1.047288\n",
      "    BA   5.0000           Naive  -  0.000154 0.000323 0.000271        0.860970      1.245594       1.141241\n",
      "  AAPL   5.0000  GA-LSTM (k=20) 20  0.001071 0.003058 0.004439        0.498372      0.985445       1.189553\n",
      "    BA   5.0000      RF (todas)  -  0.000022 0.000849 0.000306        0.323936      2.017850       1.210930\n",
      "  AAPL   5.0000  GA-LSTM (k=30) 30  0.001061 0.003398 0.005724        0.481504      1.038004       1.303643\n",
      "    GE   5.0000   GA-LSTM (k=5)  5  0.000876 0.000640 0.002062        0.898139      0.767463       1.375112\n",
      "  AAPL   5.0000    LSTM (todas)  -  0.000731 0.003139 0.007308        0.429896      1.000055       1.451665\n",
      "    GE   5.0000  GA-LSTM (k=10) 10  0.000792 0.000601 0.002437        0.853624      0.744036       1.497792\n",
      "    GE   5.0000  GA-LSTM (k=20) 20  0.000740 0.000561 0.003093        0.825019      0.718790       1.686074\n",
      "    GE   5.0000  GA-LSTM (k=30) 30  0.000712 0.000559 0.003299        0.809693      0.717586       1.742053\n",
      "    BA   5.0000   GA-LSTM (k=5)  5  0.000415 0.000944 0.000778        1.410605      2.128252       1.931834\n",
      "    BA   5.0000  GA-LSTM (k=10) 10  0.000435 0.001000 0.000795        1.444220      2.189606       1.952452\n",
      "    GE   5.0000    LSTM (todas)  -  0.000645 0.000555 0.004540        0.770075      0.714630       2.021169\n",
      "    BA   5.0000  GA-LSTM (k=20) 20  0.000476 0.001130 0.000877        1.509556      2.326099       2.049692\n",
      "    BA   5.0000  GA-LSTM (k=30) 30  0.000465 0.001050 0.000945        1.494106      2.242881       2.129089\n",
      "    BA   5.0000    LSTM (todas)  -  0.000568 0.001105 0.001589        1.634063      2.301506       2.756906\n",
      "    BA   5.0000 PCA-SVR (todas)  -  0.000065 0.003019 0.002334        0.556750      3.805929       3.346557\n",
      "    GE   5.0000      RF (todas)  -  0.000053 0.000397 0.053917        0.220168      0.604766       7.045912\n",
      "  AAPL   5.0000      RF (todas)  -  0.000011 0.060215 0.406534        0.058616      4.381618      11.384931\n",
      "    GE   5.0000 PCA-SVR (todas)  -  0.000080 0.006291 0.290949        0.270840      2.406815      16.367457\n",
      "  AAPL   5.0000 PCA-SVR (todas)  -  0.000045 0.321869 1.011495        0.120064     10.130283      17.958237\n"
     ]
    }
   ],
   "source": [
    "symbol_to_path = {\n",
    "    \"AAPL\": \"Dataset/Stocks/aapl.us.txt\",\n",
    "    \"GE\": \"Dataset/Stocks/ge.us.txt\",\n",
    "    \"BA\":\"Dataset/Stocks/ba.us.txt\",\n",
    "}\n",
    "\n",
    "df_multi = run_multi_asset_report(\n",
    "    symbol_to_path=symbol_to_path,\n",
    "    start_date=\"2000-01-01\",\n",
    "    end_date=\"2010-12-31\",\n",
    "    ks=(5, 10, 20, 30),\n",
    "    lookbacks=(5,),\n",
    "    runs=3,\n",
    "    ga_cfg=GAConfig(\n",
    "        pop_size=100,\n",
    "        p_crossover=0.8,\n",
    "        p_mutation=0.003,\n",
    "        generations=100,\n",
    "        n_points_cx=4,\n",
    "        elitism=0,\n",
    "        min_features=3,\n",
    "        n_splits_cv=5,\n",
    "        random_state=123,\n",
    "    ),\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.1,\n",
    ")\n",
    "\n",
    "# Mostrar resumen completo de todos los resultados\n",
    "display_results_summary(df_multi)\n",
    "\n",
    "# Tambi√©n mostrar tabla completa bien formateada\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TABLA COMPLETA DE TODOS LOS RESULTADOS\")\n",
    "print(\"=\" * 100)\n",
    "display_table_all = display_results_table(df_multi, sort_by=\"test_rmse_real\", ascending=True)\n",
    "print(display_table_all.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
